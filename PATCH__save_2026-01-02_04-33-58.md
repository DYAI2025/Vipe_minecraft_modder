1. Executive Summary Contracts-first: Erst Schnittstellen/Contracts festnageln, dann Implementierungen austauschen → minimiert Blocker & Rework.  Core zuerst: Domain/Schema/Validation/Reducer als „Single Source of Truth“ stabilisieren, bevor IPC/Exporter/UI refactored werden.  Lean-by-deletion: Alles, was keinen direkten Nutzen für MVP/DoD hat (Stubs, Speculative Generality), konsequent entfernen.  Inkrementell & reversibel: Jeder Schritt ein kleiner Commit, test-/buildbar, mit klarer Rückroll-Story. Gesamtbewertung (Strategie-Reife): Akzeptabel → mit Contracts+Phasen sauber zu „Gut“ bringbar.  2. Findings ID Kategorie Stelle Beschreibung Schweregrad Risiko F1 Coupling Systemweit Unklare/instabile Grenzen zwischen Domain ↔ IPC ↔ Export ↔ UI führen zu Blockern High High F2 Testability Vor Refactor Refactor ohne Sicherheitsnetz (Tests/Smokes) erhöht Regressionsrisiko High Medium F3 Cohesion Module „God“-Files/Platzhalter/Stubs verhindern klare Verantwortlichkeiten Medium Medium F4 Duplication Contracts/Types Doppelte Typdefinitionen (Domain vs Renderer) driften auseinander Medium Medium F5 Complexity Pipeline/IO IO/Errors/Progress ohne einheitliches Error-Envelope wird schwer debuggbar Medium Medium (Die konkreten Refactor-Prioritäten/Phasen sind bereits als saubere Reihenfolge dokumentiert; wir nutzen sie als Backbone.)  3. Refactoring-Plan (lean, modular, ohne Blocker) „Definition of Done“ + Contracts fixieren (1 Commit)  Aktion: docs/contracts als einzige Wahrheit deklarieren (Schema/IPC/Manifest/Error-Codes).  Ziel: Keine Diskussionen „wie sollte es sein“ während Implementierung.  Risiko: Low  Rückroll: Commit revert  Core Domain stabilisieren (Schema + validate + reducer + actions)  Aktion: Zod-Schema fertig, semantische Validation, deterministischer Reducer inkl. Undo/Redo; Action-Union ohne any.  Ziel: Alles andere kann sich darauf verlassen; reduziert Blocker in IPC/Exporter/UI.  Risiko: Medium  Rückroll: Revert pro Sub-Commit (Schema/Validate/Reducer getrennt)  ID-Policy entscheiden und „hart“ machen  Aktion: Empfehlung: IDs immutable (UI read-only, „Duplicate + Delete“ statt Rename).  Ziel: Verhindert kaputte Referenzen → massiv weniger Komplexität.  Risiko: Medium (UI-Verhalten ändert sich)  Rückroll: Feature-Flag/Toggle oder zurück zum alten Editor-Flow  IPC & Persistence als Adapter-Schicht (Main ↔ Renderer)  Aktion: Save/Load strikt nach Spec + Workspace-Sandbox + atomisches Schreiben + einheitliches Error-Envelope.  Ziel: „Funktional“ und robust, ohne UI-Workarounds.  Risiko: Medium  Rückroll: Alte Handler parallel lassen (kurz) oder revert  Exporter deterministisch machen (Manifest v1)  Aktion: Exporter generiert exakt den Tree, stable JSON ordering, Textures prefer dataUri.  Ziel: Build reproduzierbar; Debugging/Tests planbar.  Risiko: Medium  Rückroll: Exporter intern schrittweise: Template-copy → json-gen → textures → java-gen  Pipeline Reliability (Progress + Error-Mapping + Cleanup)  Aktion: pipeline:start validiert zuerst; Status-Events konsistent; Errors sauber gemappt.  Ziel: Keine „hängt“-Zustände, klare UX.  Risiko: Medium  Rückroll: Alte Pipeline-Implementierung per Branch/Tag halten  Lean-Regeln (damit’s nicht ausufert):  Jede Änderung muss einen konkreten Nutzen für DoD liefern (sonst löschen/verschieben).  Keine „Frameworks für später“, keine abstrakten „vielleicht“-Layer (Speculative Generality).  Erst Tests/Smokes, dann Struktur bewegen.  4. Patch (als minimaler Anker im Repo) Annahme: Du willst die Strategie als Repo-artefakt festhalten (ohne Code-Umbruch).  --- /dev/null +++ docs/refactoring/strategy-v1.md @@ +# Refactoring Strategy v1 (Lean + Modular) + +## Ziel +Modulare, saubere Ordnung ohne Blocker: klare Boundaries, deterministische Builds, kurze Feedback-Loops. + +## Prinzipien +- Contracts-first (Schema/IPC/Manifest/Error-Codes) +- Core-domain zuerst (Schema + Validation + Reducer) +- Adapter-Schichten: IO/IPC/Exporter sind austauschbar, Domain bleibt stabil +- Kleine Commits, jederzeit revertbar +- Delete-first: Stubs/Dead code raus, keine speculative abstractions + +## Reihenfolge (MVP) +1) Repo Hygiene + Smoke Commands +2) Core-Model finalisieren (Schema/Validate/Reducer/Actions + Tests) +3) ID-Policy festlegen (empfohlen: immutable IDs) +4) Save/Load via IPC (Sandbox + atomic write) +5) Exporter Manifest v1 deterministisch +6) Pipeline Progress + Error Mapping + Cleanup + +## Definition of Done (pro Schritt) +- Tests gruen +- Build gruen +- Keine Platzhalter/Stubs in betroffenen Files +- Fehlerbilder ueber Error-Envelope sichtbar 5. Verifikation ℹ️ Status: Nicht ausgeführt (hier nur Strategie, keine Tests gelaufen)  Empfohlen (entsprechend eurer Phasen/DoD):  Core: pnpm -C packages/core-model test  Exporter: pnpm -C packages/exporter test  Testbot: pnpm -C packages/testbot test  Repo-smoke (optional): pnpm -r build && pnpm -r test  Manuell (MVP):  Workspace wählen → Save → App neu starten → Load identisch → Pipeline starten (export/build/test)  6. Risiken/Alternativen/Rollback Risiko: Zu frühes „Aufteilen“ erzeugt mehr Dateien ohne bessere Boundaries → Mitigation: erst Contracts + Core stabil, dann Adapter.  Risiko: ID-Rename-Feature verursacht Ref-Update-Komplexität → Alternative: immutable IDs (empfohlen).  Risiko: Exporter/Pipeline-Änderungen schwer debugbar ohne Logs → Mitigation: einheitliches Error-Envelope + Status-Events.  Rollback: pro Schritt git revert <commit>; für größere Umstellungen: Branch-by-Abstraction (alt+neu parallel, dann umschalten).  Wenn du willst, kann ich als nächsten Schritt diese Strategie auf deinen konkreten Code anwenden (z.B. Core-Model zuerst) und dir einen echten Diff pro Datei erstellen – ohne „unnötige Teile“, strikt nach euren Contracts/Phasen.  Du: ja REFACT_DYAI-Refactoring_GPTv1 sagte:  Nachgedacht für 3m 8s 1. Executive Summary Ich setze Phase 1 (Core Domain Truth) sofort um: packages/core-model bekommt Schema + semantische Validation + Actions + Reducer als Single Source of Truth (lean, ohne Stubs).  Blocker-Vermeidung: Core ist pure TS (keine Electron/FS-Abhängigkeiten) → andere Pakete können sauber darauf aufbauen.  Direkt nutzbarer Patch: Vollständige File-Rewrites/Neuanlagen für schema.ts, validate.ts, actions.ts, reducer.ts, index.ts + minimale Tests (nicht verifiziert, da Repo-Code hier nicht vorliegt).  Gesamtbewertung: Verbesserungsbedürftig → mit dem Core-Paket wird’s strukturell „Gut“ (klare Boundaries, weniger Drift/Chaos).  Annahme (nicht verifiziert): Monorepo mit pnpm, TypeScript, zod ist verfügbar, Tests laufen via pnpm -C packages/core-model test.  2. Findings ID Kategorie Stelle Beschreibung Schweregrad Risiko F1 Coupling Domain überall Domain-Types/Validation sind (vermutlich) verteilt → Drift/Inkonsistenzen High High F2 Testability Vor Refactor Kein stabiler „Core“ als Testanker → Refactor wird riskant High Medium F3 Duplication Types/Schemas Doppelte Definitionen (Renderer/Exporter/Main) Medium Medium F4 Complexity Updates Ohne deterministischen Reducer wird Undo/Redo & State-Updates fehleranfällig Medium Medium F5 Cohesion Packages „Stubs/Optional AI“ in falschen Schichten erzeugen Noise/Blocker Medium Medium 3. Refactoring-Plan (klein, reversibel, commitbar) Aktion: packages/core-model als einzige Domain-Quelle etablieren (schema, validate, actions, reducer). Ziel: Einheitliche Wahrheit, weniger Blocker in IPC/Exporter/UI. Risiko: Medium Rückroll: Commit revert (isoliert, keine App-Änderungen nötig).  Aktion: Semantische Regeln nur in validate.ts (Schema bleibt strukturell). Ziel: Saubere Trennung: parse/shape vs business invariants. Risiko: Low Rückroll: Revert file.  Aktion: Reducer deterministisch + Undo/Redo History im Core. Ziel: UI wird simpel: dispatch → state. Risiko: Medium Rückroll: Reducer-Commit revert.  Aktion: Danach (separat): Electron/Main IPC importiert validateProject (Phase 2), Exporter importiert ProjectFile (Phase 3). Ziel: Adapter-Schichten sauber, keine zyklischen Abhängigkeiten. Risiko: Medium Rückroll: Adapter-Commits revert.  4. Patch Hinweis: Da du nur Specs hochgeladen hast (kein Repo-Quellcode), ist das ein direkter, copy-pastebarer Patch-Vorschlag. Pfade ggf. an deine Repo-Struktur anpassen.  --- /dev/null +++ packages/core-model/src/schema.ts @@ +import { z } from "zod"; + +// --------------------------- +// Primitive contracts +// --------------------------- +export const EntityIdSchema = z.string().regex(/^[a-z0-9_]+$/, "EntityId must match ^[a-z0-9_]+$"); +export type EntityId = z.infer<typeof EntityIdSchema>; + +export const ModIdSchema = z +  .string() +  .regex(/^[a-z][a-z0-9_]{1,63}$/, "ModId must match ^[a-z][a-z0-9_]{1,63}$"); +export type ModId = z.infer<typeof ModIdSchema>; + +export const NamespacedRefSchema = z +  .string() +  .regex(/^[a-z0-9_]+:[a-z0-9_/]+$/, "NamespacedRef must match ^[a-z0-9_]+:[a-z0-9_/]+$"); +export type NamespacedRef = z.infer<typeof NamespacedRefSchema>; + +// --------------------------- +// Domain specs +// --------------------------- +export const TextureSpecSchema = z.union([ +  z.object({ +    source: z.literal("preset"), +    value: z.string().min(1), +  }), +  z.object({ +    source: z.literal("dataUri"), +    value: z.string().min(1), +  }), +]); +export type TextureSpec = z.infer<typeof TextureSpecSchema>; + +export const BlockSpecSchema = z.object({ +  id: EntityIdSchema, +  name: z.string().min(1).max(50), +  properties: z.object({ +    hardness: z.number(), // semantic clamps in validate.ts if desired +    luminance: z.number().int().min(0).max(15), +    transparent: z.boolean(), +  }), +  texture: TextureSpecSchema, +}); +export type BlockSpec = z.infer<typeof BlockSpecSchema>; + +export const ItemSpecSchema = z.object({ +  id: EntityIdSchema, +  name: z.string().min(1).max(50), +  itemType: z.enum(["gem", "sword", "tool", "food"]), +  properties: z.object({ +    maxStackSize: z.number().int().min(1).max(64), +    attackDamage: z.number(), +  }), +  texture: TextureSpecSchema, +}); +export type ItemSpec = z.infer<typeof ItemSpecSchema>; + +const RecipeKeyCharSchema = z.string().regex(/^[A-Z0-9]$/, "Recipe key must be a single A-Z or 0-9 char"); + +export const RecipeSpecSchema = z.object({ +  id: EntityIdSchema, +  type: z.literal("shaped"), +  pattern: z.array(z.string().min(1).max(3)).min(1).max(3), +  key: z.record(RecipeKeyCharSchema, NamespacedRefSchema), +  result: z.object({ +    item: NamespacedRefSchema, +    count: z.number().int().min(1).max(64), +  }), +}); +export type RecipeSpec = z.infer<typeof RecipeSpecSchema>; + +export const ProjectMetaSchema = z.object({ +  modId: ModIdSchema, +  name: z.string().min(1).max(50), +  version: z.string().min(1).max(20), +  author: z.string().max(50).optional(), +  description: z.string().max(300).optional(), +  createdAt: z.string().optional(), +  updatedAt: z.string().optional(), +}); +export type ProjectMeta = z.infer<typeof ProjectMetaSchema>; + +export const ProjectFileSchema = z.object({ +  schemaVersion: z.literal(1), +  meta: ProjectMetaSchema, +  blocks: z.record(EntityIdSchema, BlockSpecSchema).default({}), +  items: z.record(EntityIdSchema, ItemSpecSchema).default({}), +  recipes: z.record(EntityIdSchema, RecipeSpecSchema).default({}), +}); +export type ProjectFile = z.infer<typeof ProjectFileSchema>; --- /dev/null +++ packages/core-model/src/validate.ts @@ +import { ProjectFileSchema, type ProjectFile, type NamespacedRef } from "./schema"; + +export type ValidationError = { +  code: "E_VALIDATION"; +  path: string; // json-pointer-ish, e.g. "/recipes/r1/key/R" +  message: string; +  details?: string; +}; + +export type ValidateOk = { ok: true; project: ProjectFile }; +export type ValidateFail = { ok: false; errors: ValidationError[] }; + +type Options = { +  // recommended v1: keep default false to avoid blocking existing projects +  disallowBlockItemIdCollision?: boolean; +}; + +function ptr(path: Array<string | number>): string { +  return "/" + path.map(String).join("/"); +} + +function err(path: Array<string | number>, message: string, details?: string): ValidationError { +  return { code: "E_VALIDATION", path: ptr(path), message, details }; +} + +function splitNs(ref: NamespacedRef): { ns: string; id: string } { +  const [ns, ...rest] = ref.split(":"); +  return { ns, id: rest.join(":") }; +} + +export function validateProject(input: unknown, options: Options = {}): ValidateOk | ValidateFail { +  const parsed = ProjectFileSchema.safeParse(input); +  if (!parsed.success) { +    const errors = parsed.error.issues.map((i) => +      err(i.path, i.message, i.code) +    ); +    return { ok: false, errors }; +  } + +  const project = parsed.data; +  const errors: ValidationError[] = []; +  const modId = project.meta.modId; + +  // 1) record key must equal value.id +  for (const [k, v] of Object.entries(project.blocks)) { +    if (k !== v.id) errors.push(err(["blocks", k, "id"], "Block key must equal block.id")); +  } +  for (const [k, v] of Object.entries(project.items)) { +    if (k !== v.id) errors.push(err(["items", k, "id"], "Item key must equal item.id")); +  } +  for (const [k, v] of Object.entries(project.recipes)) { +    if (k !== v.id) errors.push(err(["recipes", k, "id"], "Recipe key must equal recipe.id")); +  } + +  // 2) texture rules +  const presetAllowlist = new Set(["rock", "wood", "gem", "metal", "grass", "sand"]); +  const checkTexture = (pathBase: Array<string | number>, tex: any) => { +    if (tex?.source === "preset") { +      if (!presetAllowlist.has(tex.value)) { +        errors.push(err([...pathBase, "value"], "Unknown texture preset", `Allowed: ${[...presetAllowlist].join(", ")}`)); +      } +      return; +    } +    if (tex?.source === "dataUri") { +      if (typeof tex.value !== "string" || !tex.value.startsWith("data:image/png;base64,")) { +        errors.push(err([...pathBase, "value"], "dataUri must start with data:image/png;base64,")); +      } +      return; +    } +    errors.push(err(pathBase, "Invalid texture spec")); +  }; + +  for (const [id, b] of Object.entries(project.blocks)) { +    checkTexture(["blocks", id, "texture"], b.texture); +  } +  for (const [id, it] of Object.entries(project.items)) { +    checkTexture(["items", id, "texture"], it.texture); +  } + +  // 3) recipe semantics +  const hasOwn = (entityId: string) => Boolean(project.blocks[entityId] || project.items[entityId]); + +  const checkRef = (pathBase: Array<string | number>, ref: NamespacedRef) => { +    const { ns, id } = splitNs(ref); +    if (ns === "minecraft") return; +    if (ns !== modId) { +      errors.push(err(pathBase, "Only minecraft:* or <modId>:* references allowed", `Expected namespace: ${modId}`)); +      return; +    } +    if (!hasOwn(id)) { +      errors.push(err(pathBase, "Reference points to missing block/item", ref)); +    } +  }; + +  const allowedPatternChar = /^[A-Z0-9 ]$/; +  for (const [rid, r] of Object.entries(project.recipes)) { +    // chars allowed + every non-space char must be in key +    for (let rowIdx = 0; rowIdx < r.pattern.length; rowIdx++) { +      const row = r.pattern[rowIdx] ?? ""; +      for (let col = 0; col < row.length; col++) { +        const ch = row[col]!; +        if (!allowedPatternChar.test(ch)) { +          errors.push(err(["recipes", rid, "pattern", rowIdx], "Pattern may only contain A-Z, 0-9 or space", `Found: ${JSON.stringify(ch)}`)); +          continue; +        } +        if (ch !== " " && !r.key[ch]) { +          errors.push(err(["recipes", rid, "key", ch], "Pattern uses a char that is missing in key")); +        } +      } +    } + +    // key refs +    for (const [k, ref] of Object.entries(r.key)) { +      checkRef(["recipes", rid, "key", k], ref as NamespacedRef); +    } +    // result ref +    checkRef(["recipes", rid, "result", "item"], r.result.item); +  } + +  // 4) optional: disallow collisions between blocks/items ids +  if (options.disallowBlockItemIdCollision) { +    for (const id of Object.keys(project.blocks)) { +      if (project.items[id]) { +        errors.push(err(["items", id, "id"], "Id collision: same id used in blocks and items")); +      } +    } +  } + +  if (errors.length > 0) return { ok: false, errors }; +  return { ok: true, project }; +} --- /dev/null +++ packages/core-model/src/actions.ts @@ +import type { BlockSpec, EntityId, ItemSpec, ProjectFile, RecipeSpec } from "./schema"; + +export type KidAction = +  | { type: "LOAD_PROJECT"; project: ProjectFile } +  | { type: "UNDO" } +  | { type: "REDO" } +  | { type: "CREATE_BLOCK"; block: BlockSpec } +  | { type: "UPDATE_BLOCK"; id: EntityId; patch: Partial<Omit<BlockSpec, "id">> } +  | { type: "DELETE_BLOCK"; id: EntityId } +  | { type: "CREATE_ITEM"; item: ItemSpec } +  | { type: "UPDATE_ITEM"; id: EntityId; patch: Partial<Omit<ItemSpec, "id">> } +  | { type: "DELETE_ITEM"; id: EntityId } +  | { type: "CREATE_RECIPE"; recipe: RecipeSpec } +  | { type: "UPDATE_RECIPE"; id: EntityId; patch: Partial<Omit<RecipeSpec, "id">> } +  | { type: "DELETE_RECIPE"; id: EntityId }; + +export function isDomainChange(a: KidAction): boolean { +  switch (a.type) { +    case "UNDO": +    case "REDO": +      return false; +    default: +      return true; +  } +} --- /dev/null +++ packages/core-model/src/reducer.ts @@ +import type { KidAction } from "./actions"; +import type { ProjectFile } from "./schema"; + +export type HistoryState = { past: ProjectFile[]; future: ProjectFile[] }; + +export type AppState = { +  project: ProjectFile; +  history: HistoryState; +  lastAction: KidAction | null; +}; + +export function projectReducer(project: ProjectFile, action: KidAction): ProjectFile { +  switch (action.type) { +    case "LOAD_PROJECT": +      return action.project; + +    case "CREATE_BLOCK": { +      const id = action.block.id; +      return { ...project, blocks: { ...project.blocks, [id]: action.block } }; +    } +    case "UPDATE_BLOCK": { +      const current = project.blocks[action.id]; +      if (!current) return project; +      return { +        ...project, +        blocks: { ...project.blocks, [action.id]: { ...current, ...action.patch, id: current.id } }, +      }; +    } +    case "DELETE_BLOCK": { +      if (!project.blocks[action.id]) return project; +      const { [action.id]: _, ...rest } = project.blocks; +      return { ...project, blocks: rest }; +    } + +    case "CREATE_ITEM": { +      const id = action.item.id; +      return { ...project, items: { ...project.items, [id]: action.item } }; +    } +    case "UPDATE_ITEM": { +      const current = project.items[action.id]; +      if (!current) return project; +      return { +        ...project, +        items: { ...project.items, [action.id]: { ...current, ...action.patch, id: current.id } }, +      }; +    } +    case "DELETE_ITEM": { +      if (!project.items[action.id]) return project; +      const { [action.id]: _, ...rest } = project.items; +      return { ...project, items: rest }; +    } + +    case "CREATE_RECIPE": { +      const id = action.recipe.id; +      return { ...project, recipes: { ...project.recipes, [id]: action.recipe } }; +    } +    case "UPDATE_RECIPE": { +      const current = project.recipes[action.id]; +      if (!current) return project; +      return { +        ...project, +        recipes: { ...project.recipes, [action.id]: { ...current, ...action.patch, id: current.id } }, +      }; +    } +    case "DELETE_RECIPE": { +      if (!project.recipes[action.id]) return project; +      const { [action.id]: _, ...rest } = project.recipes; +      return { ...project, recipes: rest }; +    } + +    case "UNDO": +    case "REDO": +      // handled in rootReducer +      return project; +  } +} + +export function rootReducer(state: AppState, action: KidAction): AppState { +  switch (action.type) { +    case "UNDO": { +      const prev = state.history.past[state.history.past.length - 1]; +      if (!prev) return { ...state, lastAction: action }; +      const past = state.history.past.slice(0, -1); +      const future = [state.project, ...state.history.future]; +      return { project: prev, history: { past, future }, lastAction: action }; +    } +    case "REDO": { +      const next = state.history.future[0]; +      if (!next) return { ...state, lastAction: action }; +      const future = state.history.future.slice(1); +      const past = [...state.history.past, state.project]; +      return { project: next, history: { past, future }, lastAction: action }; +    } +    case "LOAD_PROJECT": { +      const project = projectReducer(state.project, action); +      return { project, history: { past: [], future: [] }, lastAction: action }; +    } +    default: { +      const nextProject = projectReducer(state.project, action); +      if (nextProject === state.project) return { ...state, lastAction: action }; +      return { +        project: nextProject, +        history: { past: [...state.history.past, state.project], future: [] }, +        lastAction: action, +      }; +    } +  } +} --- /dev/null +++ packages/core-model/src/index.ts @@ +export * from "./schema"; +export * from "./validate"; +export * from "./actions"; +export * from "./reducer"; --- /dev/null +++ packages/core-model/src/__tests__/schema.test.ts @@ +import { describe, expect, it } from "vitest"; +import { ProjectFileSchema } from "../schema"; + +describe("ProjectFileSchema", () => { +  it("accepts a minimal valid project", () => { +    const ok = ProjectFileSchema.safeParse({ +      schemaVersion: 1, +      meta: { modId: "kid_ruby_mod", name: "Ruby Mod", version: "0.1.0" }, +      blocks: {}, +      items: {}, +      recipes: {}, +    }); +    expect(ok.success).toBe(true); +  }); + +  it("rejects invalid modId", () => { +    const bad = ProjectFileSchema.safeParse({ +      schemaVersion: 1, +      meta: { modId: "Kid_Ruby_Mod", name: "Ruby Mod", version: "0.1.0" }, +      blocks: {}, +      items: {}, +      recipes: {}, +    }); +    expect(bad.success).toBe(false); +  }); +}); --- /dev/null +++ packages/core-model/src/__tests__/validate.test.ts @@ +import { describe, expect, it } from "vitest"; +import { validateProject } from "../validate"; + +describe("validateProject", () => { +  it("flags missing recipe key char used in pattern", () => { +    const res = validateProject({ +      schemaVersion: 1, +      meta: { modId: "kid_ruby_mod", name: "Ruby Mod", version: "0.1.0" }, +      blocks: {}, +      items: { +        ruby_gem: { +          id: "ruby_gem", +          name: "Ruby", +          itemType: "gem", +          properties: { maxStackSize: 64, attackDamage: 0 }, +          texture: { source: "preset", value: "gem" }, +        }, +      }, +      recipes: { +        r1: { +          id: "r1", +          type: "shaped", +          pattern: ["R  "], +          key: {}, +          result: { item: "kid_ruby_mod:ruby_gem", count: 1 }, +        }, +      }, +    }); +    expect(res.ok).toBe(false); +  }); +}); 5. Verifikation Nicht verifiziert (kein Repo/CI-Lauf hier möglich).  Empfohlen:  pnpm -C packages/core-model test  pnpm -C packages/core-model build (falls vorhanden)  Optional monorepo-smoke: pnpm -r build && pnpm -r test  Fallback manuell:  Minimalprojekt als JSON → validateProject() aufrufen → Fehlerliste prüfen.  6. Risiken/Alternativen/Rollback Risiken  vitest ist ggf. nicht euer Test-Runner → dann Tests auf Jest/Tap anpassen (Syntax minimal).  Zod-Version/Config kann abweichen (z.B. ESM/CJS) → ggf. Import-Stil anpassen.  Semantik-Checks (z.B. preset allowlist) könnten existierende Projekte brechen → deshalb im Patch bewusst nur klare Regeln, und Kollision block/item optional.  Alternativen  Strikter: collisions block/item immer error (sauberer, aber potenziell blocker).  Noch leaner: Reducer ohne History im Core → History in UI (weniger Code, aber verteilt Verantwortung).  Rollback  Jeder Schritt ist isoliert: git revert <commit> pro Datei/Commit.  Falls du erst „nur Schema+Validate“ willst: Reducer/Actions-Commits separat halten und bei Bedarf droppen.