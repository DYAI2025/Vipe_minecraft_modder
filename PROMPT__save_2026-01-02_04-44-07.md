„Zentrale Verträge (Contracts)“ aussagen.  Die Analyse der Quellen zum „Minecraft Mod Studio for Kids“ zeigt, dass „Zentrale Verträge“ (Contracts) das fundamentale architektonische Werkzeug sind, um das Repository von einem unvollständigen Prototypen (mit Platzhaltern wie ...) in ein stabiles, sicheres Produktionssystem zu überführen. Die Quellen verfolgen eine explizite „Contract-First“-Strategie: Bevor Code implementiert wird, werden die Schnittstellen zwischen den Systemkomponenten (Daten, UI, Backend, Output) rigoros festgelegt. Hier ist eine detaillierte Diskussion der vier zentralen Verträge, die in den Quellen definiert werden: 1. Der Daten-Vertrag: Project JSON Spec v1 Dieser Vertrag dient als „Single Source of Truth“ (einzige Wahrheitsquelle). Er entkoppelt die Benutzeroberfläche von der Speicher- und Build-Logik. • Zweck: Ein einziges, kanonisches Dateiformat (project.json) steuert Speichern, Laden, Undo/Redo und den Export. Es muss so strikt definiert sein, dass ungültige Zustände (z. B. kaputte Referenzen) unmöglich sind,. • Struktur & Versionierung: Das Feld schemaVersion: 1 ist zwingend erforderlich, um zukünftige Migrationen zu ermöglichen,. • Identitäten & Referenzen: Es gelten harte Regex-Regeln für IDs (z. B. ^[a-z0-9_]+$), um Kompatibilität mit Minecraft/Fabric zu sichern. Referenzen in Rezepten müssen entweder auf eigene Items (modId:*) oder Vanilla-Items (minecraft:*) zeigen. • Textur-Handling: Um die Lücke zwischen UI-Vorschau und Datei-Export zu schließen, definiert der Vertrag TextureSpec. Es wird empfohlen, Texturen idealerweise immer als dataUri (Base64 PNG) zu speichern, um den Export deterministisch zu machen,. • Entscheidung zur Immutability: Die Quellen empfehlen dringend, IDs nach der Erstellung als unveränderlich zu behandeln (Option A), um komplexe Referenz-Updates („Shotgun Surgery“) zu vermeiden. 2. Der Kommunikations-Vertrag: IPC / Bridge Spec v1 Dieser Vertrag regelt die Sicherheit an der „Trust Boundary“ (Vertrauensgrenze) zwischen dem unsicheren UI (Renderer) und dem privilegierten Hauptprozess (Electron Main). • Sicherheits-Grundsatz: Der Renderer gilt als „untrusted“. Er darf niemals direkten Zugriff auf Node.js-APIs oder das Dateisystem haben,. • Kanonische Kanäle: Die Kommunikation ist auf eine strikte „Allowlist“ von Kanälen beschränkt (z. B. project:save, pipeline:start). Unbekannte Kanäle müssen blockiert werden. • Envelope-Pattern (Umschlag): Antworten erfolgen nicht als rohe Daten, sondern in einem standardisierten Umschlag (IpcResult): entweder { ok: true, data: ... } oder { ok: false, error: ... }. Dies zwingt das UI zur sauberen Fehlerbehandlung,. • Sandbox-Zwang: Der Main-Prozess muss bei jedem Dateizugriff eine Sandbox erzwingen (via safeJoin), um „Path Traversal“-Angriffe zu verhindern. Der Renderer darf niemals absolute Pfade diktieren,. 3. Der Output-Vertrag: Exporter Manifest v1 Dieser Vertrag stellt sicher, dass der Build-Prozess deterministisch ist – also bei gleicher Eingabe immer exakt dieselbe Dateistruktur erzeugt. • Ziel: Der Exporter muss ein vollständig baufertiges Fabric-Mod-Projekt erzeugen, das Assets, Code und Konfigurationen enthält. • Struktur-Garantie: Das Manifest definiert exakt, wo Dateien liegen müssen (z. B. src/main/resources/assets/<modId>/textures/...), damit der Gradle-Build funktioniert,. • Generierung:     ◦ Platzhalter in Templates (z. B. {{MOD_ID}}) werden durch Metadaten ersetzt.     ◦ Java-Code (ModRegistry.java) und JSON-Ressourcen werden maschinell aus dem Datenmodell abgeleitet. 4. Der UX-Vertrag: Error Catalog v1 Zusätzlich zu den technischen Schnittstellen definieren die Quellen einen Vertrag für das Nutzererlebnis im Fehlerfall. • Standardisierte Codes: Es wird eine feste Liste von Fehlercodes definiert (z. B. E_VALIDATION, E_BUILD_FAILED, E_WORKSPACE_REQUIRED). Diese Codes bleiben stabil, auch wenn sich die technische Implementierung ändert,. • Kindgerechte Nachrichten: Der Vertrag trennt strikt zwischen technischen Details (für Logs) und der Nachricht für das Kind. Statt „Gradle Exit Code 1“ muss das System sagen: „Dein Mod konnte nicht gebaut werden. Lass uns das reparieren!“,. • Mapping-Regeln: Es ist festgelegt, welches technische Ereignis zu welchem Code führt (z. B. führt ein Server-Timeout zwingend zu E_TEST_FAILED). Zusammenfassende Bedeutung für das „Re-Assembly“ Die Quellen argumentieren, dass diese Verträge die Voraussetzung für den „Re-Assembly Plan“ sind. Das Repository wird nicht „einfach fertig programmiert“, sondern schichtweise basierend auf diesen Verträgen stabilisiert: 1. Phase 1: Core-Model stabilisieren (Project JSON Spec erfüllen). 2. Phase 2: Persistenz sichern (IPC Spec & Sandbox erzwingen). 3. Phase 3: Exporter reparieren (Manifest erfüllen). Analogie: Die Quellen vergleichen die Architektur implizit mit einer Bank. Der Renderer (Kunde) reicht Wünsche durch einen gesicherten Schalter (IPC Bridge) an den Angestellten (Main Process). Der Angestellte akzeptiert nur genormte Formulare (Project JSON Contract), prüft diese auf Gültigkeit und legt das Geld (Daten) dann sicher in den Tresor (Sandbox) – und gibt am Ende eine standardisierte Quittung (Error Envelope) zurück,. Welche drei Phasen sieht der strategische „Re-Assembly Plan“ vor? Wie unterscheidet sich die Handhabung von „preset“- gegenüber „dataUri“-Texturen? Welche Sicherheitsmaßnahmen implementiert „workspace.ts“ gegen „Path Traversal“-Angriffe? Diskutieren, was diese Quellen im Kontext von „Zentrale Verträge (Contracts)“ über „Project JSON Spec v1“ aussagen.  Basierend auf den vorliegenden Quellen wird die Project JSON Spec v1 als das wichtigste Fundament („Single Source of Truth“) der gesamten Systemarchitektur des „Minecraft Mod Studio for Kids“ definiert. Sie dient als harter Daten-Vertrag, der alle Komponenten – vom Editor (Renderer) über die Speicherlogik bis hin zum Exporter – entkoppelt und synchronisiert,. Hier ist eine detaillierte Diskussion der Aussagen zu diesem Vertrag: 1. Kernfunktion: Single Source of Truth Die Spezifikation (dokumentiert in docs/contracts/project-json-spec-v1.md) legt ein einziges, kanonisches Dateiformat (project.json) fest. Dieses Format ist universell verantwortlich für: • Persistenz: Speichern und Laden des Projektzustands. • Statusverwaltung: Grundlage für Undo/Redo-Operationen im Domain-State. • Export-Basis: Es dient als deterministische Eingabe für den Exporter, der daraus den Java-Code für den Fabric-Mod generiert. • Validierung: Es ersetzt die unfertigen Platzhalter („Stubs“) im Code durch ein streng validierbares Schema. 2. Strikte Struktur und Versionierung Der Vertrag definiert nicht nur eine lose JSON-Struktur, sondern erzwingt harte Regeln mittels Zod-Schemas: • Versionierung (schemaVersion: 1): Das Feld ist zwingend und muss exakt das Literal 1 enthalten.     ◦ Dies dient als „Gatekeeper“: Unbekannte Versionen werden sofort abgelehnt, um Datenkorruption zu verhindern.     ◦ Es ermöglicht zukünftige Migrationspfade, falls sich das Format ändert (z. B. zu v2), ohne alte Projekte unbrauchbar zu machen. • Metadaten: Das meta-Objekt enthält essenzielle Identitätsdaten (modId, name, version). Besonders die modId ist kritisch, da sie als technischer Namespace für alle Ressourcen dient. • Container-Logik: Daten werden in drei Hauptkategorien (blocks, items, recipes) organisiert, die als Records (Key-Value-Paare) strukturiert sind. 3. Naming-Regeln und Kompatibilität Um sicherzustellen, dass das erstellte Projekt tatsächlich als Minecraft-Mod funktioniert (und nicht beim Kompilieren abstürzt), erzwingt die Spec strikte Regex-Regeln: • EntityId: IDs für Blöcke und Items dürfen nur Kleinbuchstaben, Zahlen und Unterstriche enthalten (^[a-z0-9_]+$),. • ModId: Muss mit einem Buchstaben beginnen und darf maximal 63 Zeichen lang sein (^[a-z][a-z0-9_]{1,63}$),. • Referenzen: Verweise in Rezepten müssen entweder auf den Vanilla-Namespace (minecraft:*) oder den eigenen Mod-Namespace (modId:*) zeigen. 4. Textur-Handling (Preset vs. DataUri) Ein spezifisches Problem der Architektur war die Diskrepanz zwischen der Vorschau im Browser (Canvas) und den physischen PNG-Dateien im Export. Die Spec löst dies durch die TextureSpec: • Zwei Quellen: Eine Textur kann entweder ein preset (z. B. value: "rock") oder eine dataUri (Base64-kodiertes PNG) sein. • Empfehlung für Determinismus: Die Quellen empfehlen dringend, Texturen im UI immer in dataUri umzuwandeln und so zu speichern. Das macht den Exporter deterministisch („What You See Is What You Get“), da er lediglich den String in eine Datei schreiben muss (dataUriToBuffer), ohne Logik für Presets vorhalten zu müssen,. 5. Semantische Validierung (validateProject) Der Vertrag verlangt, dass die project.json nicht nur strukturell (Schema), sondern auch semantisch validiert wird. Das core-model muss sicherstellen: • Integrität: Der Key im JSON-Objekt muss exakt der id im Objekt entsprechen. • Referenz-Check: Jedes Item, das in einem Crafting-Rezept verwendet wird, muss tatsächlich im Projekt existieren (oder ein Vanilla-Item sein). • Fehlerbehandlung: Verletzungen dieser Regeln führen zum Fehlercode E_VALIDATION mit kindgerechten Hinweisen. 6. Strategische Entscheidung: Immutable IDs Die Quellen diskutieren intensiv das Risiko von ID-Umbenennungen. Da IDs als Schlüssel für Referenzen dienen, würde ein einfaches Umbenennen alle Verknüpfungen (z. B. in Rezepten) zerstören. • Die Policy: Die Spec empfiehlt Option A: IDs sind nach der Erstellung immutable (unveränderlich). • Umsetzung: Das UI soll kein Umbenennen erlauben, sondern stattdessen eine Funktion „Kopieren als neue ID + Löschen der alten ID“ anbieten. Dies hält den Reducer im Core-Model simpel und robust,. Zusammenfassende Analogie Man kann die Project JSON Spec v1 als die DNA des Projekts betrachten. Egal ob der Renderer (das Erscheinungsbild), der Exporter (der Körperbau) oder der Main-Process (das Gedächtnis) darauf zugreift – alle müssen sich strikt an diesen genetischen Code halten. Wenn die DNA beschädigt ist (Validierungsfehler), kann der Organismus nicht überleben (Build Failed). Daher ist die Stabilisierung dieser Spec der allererste Schritt („Phase 1“) im Wiederaufbauplan,. Welche drei Komponenten umfasst die Build-Pipeline laut Architektur-Blueprint? Wie unterscheiden sich die Textur-Quellen „preset“ und „dataUri“ technisch? Welche Sicherheitsregeln muss der Main-Prozess laut IPC-Spec erzwingen? Diskutieren, was diese Quellen im Kontext von „Project JSON Spec v1“ über „schemaVersion: 1“ aussagen.  Basierend auf den vorliegenden Quellen, insbesondere den Entwurfsdokumenten („Project JSON Spec v1“), den Implementierungs-Patches für das core-model und den Architektur-Diskussionen, fungiert das Feld schemaVersion: 1 als fundamentaler technischer Anker für die Datenintegrität des „Minecraft Mod Studio for Kids“. Die Quellen definieren dieses Feld nicht als bloße Metadaten-Information, sondern als harten Vertrag (Contract), der sicherstellt, dass die Anwendung nur kompatible Datenstrukturen verarbeitet. Hier ist eine detaillierte Diskussion der Aussagen: 1. Definition als unveränderliche Konstante Im Kontext der „Project JSON Spec v1“ ist schemaVersion ein zwingendes Top-Level-Feld in der project.json-Datei. • Single Source of Truth: Es dient dazu, das Dateiformat eindeutig zu identifizieren. Die Quellen legen fest, dass für die aktuelle Version des Systems („v1“) der Wert exakt die ganze Zahl 1 sein muss. • Technische Durchsetzung (Zod): In den Refactoring-Patches für das packages/core-model wird das Feld nicht als generische number implementiert, sondern als z.literal(1). Das bedeutet, dass der Parser (Zod) jede Datei, die keine 1 (oder gar kein Version-Feld) enthält, sofort als ungültig ablehnt, noch bevor der Rest der Struktur geprüft wird. 2. Funktion als „Gatekeeper“ bei der Validierung Die Quellen beschreiben schemaVersion als ersten Schutzwall gegen Datenkorruption und Abstürze. • Ablehnung unbekannter Versionen: Die Validierungslogik (validateProject) prüft explizit, ob die Version bekannt ist. Unbekannte Versionen (z. B. 0 aus alten Prototypen oder eine hypothetische 2 aus der Zukunft) müssen abgelehnt werden. • Schutz des Exporters: Der Exporter, der das Projekt in Java-Code umwandelt, verlässt sich darauf, dass die Datenstruktur exakt der Spezifikation v1 entspricht. Das Feld garantiert, dass keine veralteten oder inkompatiblen Strukturen in den Build-Prozess gelangen, was zu schwer debuggbaren Fehlern führen würde. 3. Strategie für Migration und Zukunftssicherheit Obwohl der Wert aktuell fest auf 1 steht, diskutieren die Quellen das Feld als Vorbereitung für zukünftige Änderungen am Datenformat. • Migrationspfad: Sollte sich das Format ändern (z. B. auf v2), dient schemaVersion als Trigger für eine Migrationsfunktion (migrate(project)), die im core-model implementiert werden müsste. • Kompatibilitäts-Logik: Der „IPC / Bridge Spec“ sieht vor, dass der Main-Process beim Laden einer Datei (project:load) prüft: Ist es Version 1? Wenn ja, validieren. Wenn nein (z. B. Version 0), muss migriert oder ein Fehler geworfen werden, bevor die Daten an den Renderer (UI) gesendet werden. 4. Abgrenzung zu anderen Versionen Die Quellen unterscheiden scharf zwischen zwei Versionsbegriffen, die nicht verwechselt werden dürfen: • schemaVersion: 1: Die Version der Dateistruktur (technisch, Integer, im Root der JSON). • meta.version: Die Version des Mods selbst (semantisch, String z. B. "0.1.0", im meta-Objekt), die vom Kind festgelegt wird. Zusammenfassung Die Quellen sagen aus, dass schemaVersion: 1 das Fundament der Daten-Verträge ist. Es transformiert die project.json von einem losen JSON-Objekt in ein versioniertes Artefakt. Durch die Implementierung als z.literal(1) wird erzwungen, dass sowohl der Editor (Renderer) als auch der Exporter immer eine garantierte Struktur vorfinden, was für das geplante „Re-Assembly“ (Wiederzusammensetzen) des Systems als kritisch eingestuft wird. Welche Rollen übernehmen Renderer und Main-Prozess laut IPC-Spec? Wie unterscheiden sich die Textur-Quellen „preset“ und „dataUri“ technisch? Welche Sicherheitsmaßnahmen verhindert Path Traversal beim Speichern von Projekten? Diskutieren, was diese Quellen im Kontext von „Project JSON Spec v1“ über „meta (modId, name, version)“ aussagen.  Basierend auf den vorliegenden Quellen, insbesondere den Dokumenten zur „Project JSON Spec v1“ und den Refactoring-Plänen („Contracts“), nehmen die Felder im meta-Objekt (modId, name, version) eine fundamentale, infrastrukturelle Rolle im System ein. Sie sind weit mehr als nur beschreibende Texte; sie definieren die technische Identität des Mods, die Namespaces für alle Assets und die Struktur des generierten Java-Codes. Hier ist eine detaillierte Diskussion dessen, was die Quellen über meta aussagen: 1. Definition als „Unveränderlicher Kern“ (Single Source of Truth) Im Kontext der „Project JSON Spec v1“ ist das meta-Objekt der Anker der Projektdatei (project.json). Die Quellen betonen, dass diese Daten die absolute Wahrheit für alle nachgelagerten Prozesse (Speichern, UI-Anzeige, Export) darstellen,. • Pflichtfelder: Die Felder modId, name und version sind zwingend erforderlich (required),. • Optionale Felder: Es gibt Platz für author, description sowie Zeitstempel (createdAt, updatedAt), die primär dokumentarischen Charakter haben,. • Schema: Die Struktur ist im core-model (Datei schema.ts) fest verankert und darf keine Platzhalter („Stubs“) mehr enthalten. 2. Die modId: Technischer Dreh- und Angelpunkt Die modId wird in den Quellen als das kritischste Feld behandelt. Sie dient als technischer Schlüssel, der das interne Datenmodell mit der externen Welt (Minecraft/Fabric) verbindet. A. Strikte Validierung (Regex) Um Kompatibilität mit dem Fabric-Loader zu gewährleisten, definieren die Quellen ein strenges Validierungsmuster für die modId: • Sie muss dem Regex ^[a-z][a-z0-9_]{1,63}$ entsprechen,. • Das bedeutet: Sie muss mit einem Buchstaben beginnen, darf nur Kleinbuchstaben, Ziffern und Unterstriche enthalten und maximal 63 Zeichen lang sein. • Verstöße gegen diese Regel führen im validateProject-Schritt sofort zum Fehlercode E_VALIDATION. B. Interner Namespace (Referenzierung) Die modId bildet den Namespace für alle im Projekt erstellten Inhalte. • Wenn ein Nutzer einen Block mit der ID ruby_block erstellt, wird dieser intern als <modId>:ruby_block referenziert. • Invariante: Die Validierungslogik prüft, ob Referenzen in Rezepten (Crafting Recipes) entweder auf den Namespace minecraft: (Vanilla-Items) oder auf den eigenen Namespace <modId>: zeigen,. Eine Änderung der modId würde somit alle internen Referenzen zerstören. 3. Rolle im Export-Prozess (Exporter Manifest) Im Kontext des „Exporter Manifest v1“ steuern die meta-Daten die Generierung des physischen Codes und der Dateistruktur. Der Exporter nutzt sie, um das generische Template in einen spezifischen Mod zu verwandeln,. • Platzhalter-Ersetzung: Im Template existieren Platzhalter, die direkt ersetzt werden:     ◦ {{MOD_ID}} → project.meta.modId     ◦ {{MOD_NAME}} → project.meta.name     ◦ {{MOD_VERSION}} → project.meta.version,. • Deterministische Java-Paketierung: Die modId bestimmt den Java-Paketpfad, um Namenskonflikte zu vermeiden. Das Paket wird zu com.kidmodstudio.<modId> (oder ähnlich deterministisch),. • Klassen-Generierung: Die Hauptklasse des Mods (ModMainClass) wird oft als PascalCase-Derivat der modId generiert (z. B. kid_ruby_mod → KidRubyMod.java). • Konfiguration: Die Datei fabric.mod.json (Metadaten für den Loader) und die Mixin-Konfiguration (<modId>.mixins.json) werden mit diesen Werten befüllt. 4. name und version Während die modId tief in die technische Architektur eingreift, haben name und version spezifische Aufgaben in der Präsentation und Versionierung: • Name: Dient der Anzeige im Spiel (in der Mod-Liste) und im UI des Studios. Das Schema erlaubt hier freiere Zeichenketten (1–50 Zeichen),. • Version: Muss vorhanden sein und sollte idealerweise dem „Semantic Versioning“ (SemVer) folgen (z. B. „0.1.0“), um Updates verwaltbar zu machen,. Zusammenfassung Die Quellen beschreiben meta (modId, name, version) nicht als beiläufige Einstellungen, sondern als das Fundament der Projektintegrität. Insbesondere die modId ist eine architektonische Konstante: Sie diktiert die Ordnerstruktur (Assets), die Java-Pakete und die Gültigkeit aller internen Verknüpfungen. Aus diesem Grund priorisiert der „Re-Assembly Plan“ (Phase 1) die Stabilisierung und Validierung dieses Metadaten-Schemas, bevor an Features wie der UI oder dem Build-Prozess gearbeitet wird,. Welche drei Komponenten umfasst die Build-Pipeline laut Architektur-Blueprint? Wie unterscheiden sich die Textur-Quellen „preset“ und „dataUri“ technisch? Welche Sicherheitsregeln muss der Main-Prozess laut IPC-Spec erzwingen? Diskutieren, was diese Quellen im Kontext von „Project JSON Spec v1“ über „Entity-IDs (Regex-Regeln)“ aussagen.  Im Kontext der „Project JSON Spec v1“ definieren die Quellen die „Entity-IDs“ als streng formatierte Identifikatoren, die als Primärschlüssel für Blöcke, Gegenstände (Items) und Rezepte dienen. Diese IDs sind entscheidend für die technische Kompatibilität mit dem Minecraft/Fabric-Ökosystem und die innere Datenkonsistenz des Projekts. Hier ist eine detaillierte Diskussion der Aussagen zu den Regex-Regeln und deren Implikationen: 1. Die strikte Regex-Regel für Entity-IDs Die Spezifikation schreibt vor, dass jede EntityId (verwendet als Schlüssel in blocks, items und recipes) einem exakten regulären Ausdruck folgen muss: • Regex: ^[a-z0-9_]+$,,,. • Erlaubte Zeichen: Ausschließlich Kleinbuchstaben (a-z), Ziffern (0-9) und Unterstriche (_),. • Beispiele: Gültig sind IDs wie ruby_block, copper_sword oder shiny_gem,. • Zweck: Diese Regel erzwingt das „Snake_Case“-Format, das für Ressourcen-Namen in Minecraft und Fabric technisch notwendig ist. Sie verhindert Probleme, die durch Leerzeichen, Sonderzeichen oder Großschreibung in Dateipfaden und Java-Code entstehen würden. 2. Abgrenzung zu anderen ID-Typen Die Quellen unterscheiden explizit zwischen der EntityId und anderen Identifikatoren, die leicht abweichende Regeln haben: • ModId: Die ID des gesamten Mods (Namespace) muss mit einem Buchstaben beginnen und hat eine Längenbeschränkung. Der Regex lautet ^[a-z][a-z0-9_]{1,63}$,,. • NamespacedRef: Referenzen innerhalb von Rezepten (z. B. auf minecraft:stick) folgen dem Muster ^[a-z0-9_]+:[a-z0-9_/]+$, wobei der Doppelpunkt den Namespace trennt und Slashes für Unterpfade erlaubt sind,. 3. Datenintegrität und Invarianten Die Regex-Regeln sind nicht nur kosmetisch, sondern Teil der strukturellen Validierung (validateProject): • Konsistenz: Es gilt die Invariante, dass der Schlüssel (Key) im JSON-Container (z. B. blocks) exakt mit dem Feld id innerhalb des Objekts übereinstimmen muss,,. • Validierung: Das Zod-Schema im core-model muss diese Regex-Regeln technisch durchsetzen, um sicherzustellen, dass keine ungültigen IDs in den Build-Prozess gelangen, was zu Java-Kompilierungsfehlern führen würde,. 4. Die „Immutable“-Strategie (ID Rename Policy) Ein kritischer Aspekt, den die Quellen im Kontext der IDs diskutieren, ist die Gefahr von Umbenennungen. Da die EntityId als Referenzschlüssel (z. B. in Rezepten oder zukünftigen Loot-Tabellen) verwendet wird, führt eine Änderung der ID zu „gebrochenen Referenzen“,. • Empfehlung (Option A): Die Spezifikation empfiehlt dringend, IDs nach der Erstellung als unveränderlich (immutable) zu behandeln,. • Umsetzung: Das UI (EditorPanel) soll IDs als „Read-only“ anzeigen. Wenn ein Nutzer eine ID „umbenennen“ möchte, muss dies technisch durch eine „Kopieren + Löschen“-Aktion gelöst werden (neues Objekt mit neuer ID erstellen, altes löschen), anstatt die ID direkt zu editieren,,. Zusammenfassend dienen die strikten Regex-Regeln für Entity-IDs dazu, das Datenmodell zu einer verlässlichen „Single Source of Truth“ zu machen und die Komplexität im Exporter und Reducer zu minimieren, indem sie ungültige Zustände von vornherein ausschließen,. Welche zwei Textur-Quellen unterscheidet die „Project JSON Spec v1“? Warum wird empfohlen, IDs nach der Erstellung unveränderlich zu machen? Welche Sicherheitsregeln muss der Main-Prozess laut IPC-Spec erzwingen? Diskutieren, was diese Quellen im Kontext von „Project JSON Spec v1“ über „TextureSpec (Preset/DataUri)“ aussagen.  Basierend auf den Quellen, insbesondere der „Project JSON Spec v1“ und den zugehörigen Implementierungsplänen, wird TextureSpec als der zentrale Datentyp definiert, der die visuelle Darstellung von Blöcken und Items im „Minecraft Mod Studio“ steuert. Die Spezifikation zielt darauf ab, die Lücke zwischen der dynamischen Vorschau im Renderer (React/Three.js) und dem statischen Dateiexport (Java/PNG) zu schließen. Hier ist eine detaillierte Diskussion dessen, was die Quellen über TextureSpec aussagen: 1. Definition als Union-Type (Die zwei Varianten) Die „Project JSON Spec v1“ definiert TextureSpec als einen Union Type, der zwei exklusive Zustände annehmen kann. Dies dient dazu, sowohl einfache Benutzerauswahlen (Presets) als auch komplexe, generierte Grafiken (DataURIs) in einem einzigen Schema abzubilden,. • Variante A: Preset     ◦ Struktur: { "source": "preset", "value": "string" },.     ◦ Bedeutung: Der Wert verweist auf eine vordefinierte Textur-Vorlage, die intern im System bekannt ist (z. B. „rock“, „wood“, „gem“).     ◦ Validierung: Die Quellen definieren eine strikte „Allowlist“ (Erlaubnisliste) für Presets. In der Version 1 sind Werte wie rock, wood, gem, metal, grass und sand vorgesehen. Unbekannte Werte müssen bei der Validierung abgelehnt oder auf einen Fallback gemappt werden,. • Variante B: DataUri     ◦ Struktur: { "source": "dataUri", "value": "data:image/png;base64,..." },.     ◦ Bedeutung: Der Wert enthält die rohen Bilddaten als Base64-kodierten String. Dies ermöglicht es, Texturen, die im Editor dynamisch generiert (z. B. via Canvas im TextureGenerator) oder vom Benutzer gezeichnet wurden, direkt in der Projektdatei zu speichern.     ◦ Validierung: Der String muss zwingend mit dem Präfix data:image/png;base64, beginnen, um vom Exporter verarbeitet werden zu können,. 2. Strategische Empfehlung: „DataUri First“ Obwohl die Spezifikation beide Varianten erlaubt, sprechen die Quellen eine klare Architektur-Empfehlung für die Persistenz aus, um den Export-Prozess deterministisch zu gestalten. • Das Problem: Wenn Texturen nur als „Preset“ gespeichert werden, müsste der Exporter (der im Main-Process oder als separates Paket läuft) genau wissen, wie er aus dem Wort „rock“ dieselbe Pixelgrafik generiert wie der Renderer (UI). Dies würde eine Codeduplizierung der Generierungslogik erfordern oder eine komplexe Abhängigkeit schaffen. • Die Lösung: Die Quellen empfehlen: „Renderer speichert immer dataUri (egal ob preset oder nicht)“. Das bedeutet, wenn der Nutzer im UI das Preset „Rock“ wählt, generiert der TextureGenerator im Hintergrund sofort das Bild und speichert den Base64-String in das JSON. • Vorteil für den Exporter: Der Exporter muss dann keine Logik mehr über Presets besitzen. Er führt lediglich eine triviale Operation aus: dataUriToBuffer(pngDataUri) -> write bytes to .png. Dies garantiert das „What You See Is What You Get“-Prinzip (WYSIWYG),. 3. Implementierung im Schema (Zod) Die Quellen enthalten konkrete Code-Patches für das core-model, die zeigen, wie TextureSpec technisch umgesetzt wird. Das Zod-Schema in schema.ts erzwingt die Struktur strikt: export const TextureSpecSchema = z.union([   z.object({     source: z.literal("preset"),     value: z.string().min(1),   }),   z.object({     source: z.literal("dataUri"),     value: z.string().min(1),   }), ]); . Dies stellt sicher, dass ungültige Textur-Objekte (z. B. fehlende source oder falsche Typen) bereits beim Laden oder Speichern abgelehnt werden, bevor sie das System destabilisieren können. 4. Rolle im Export-Manifest Im Kontext des „Exporter Manifest v1“ diktiert die TextureSpec, wo die resultierenden Dateien im Fabric-Mod-Ordner landen. • Unabhängig davon, ob die Quelle ein Preset oder eine DataUri war, ist das Endergebnis im Dateisystem immer eine .png-Datei unter assets/<modId>/textures/block/ oder assets/<modId>/textures/item/,. • Der Exporter ist dafür verantwortlich, diese Umwandlung (String zu Datei) vorzunehmen, wobei er sich auf die Validierung des core-model verlässt, dass es sich um gültige PNG-Daten handelt. Zusammenfassung Die TextureSpec ist in der „Project JSON Spec v1“ das Bindeglied zwischen der flüchtigen Vorschau im Browser und dem permanenten Mod-Asset. Die Quellen favorisieren dabei eindeutig den Ansatz, DataURIs als primäres Speicherformat zu nutzen, um die Komplexität aus dem Backend (Exporter) fernzuhalten und die visuelle Konsistenz zu garantieren. Presets dienen primär als UI-Hilfsmittel zur Auswahl, sollen aber idealerweise sofort in Bilddaten „gebacken“ werden. Welche drei Phasen sieht der „Wiring Plan“ zur Systemstabilisierung vor? Welche Sicherheitsregeln muss der Main-Prozess laut IPC-Spec erzwingen? Wie unterscheidet sich die „ID Rename Policy“ zwischen Option A und B? Diskutieren, was diese Quellen im Kontext von „Zentrale Verträge (Contracts)“ über „IPC / Bridge Spec“ aussagen.  Basierend auf den vorliegenden Quellen wird die „IPC / Bridge Spec“ im Kontext der „Zentralen Verträge (Contracts)“ als das fundamentale Bindeglied definiert, das die Sicherheit, Typsicherheit und Entkopplung zwischen der Benutzeroberfläche (Renderer) und der Systemlogik (Main Process) gewährleistet. Die Quellen beschreiben diesen Vertrag nicht nur als technische Schnittstelle, sondern als harte Sicherheitsgrenze („Trust Boundary“), die vor der eigentlichen Implementierung festgelegt werden muss („Contract-First“-Strategie). Hier ist eine detaillierte Diskussion der Aussagen: 1. Die Bridge als Sicherheits-Grenze (Trust Boundary) Die Quellen definieren die Architektur so, dass der Renderer (React UI) grundsätzlich als „untrusted“ (nicht vertrauenswürdig) eingestuft wird,. • Isolierung: Der Renderer darf keinen direkten Zugriff auf Node.js-APIs, das Dateisystem oder Kindprozesse haben. • Gatekeeper: Die Datei bridge.ts fungiert als Schleuse. Sie exponiert über contextBridge eine globale API (window.KidMod), die die Kommunikation kanalisiert. • Enforcement: Ein kritischer Befund der Analyse ist, dass die „Allowlist“ erlaubter Kanäle (z. B. VALID_CHANNELS) im aktuellen Code zwar existiert, aber nicht strikt durchgesetzt wird. Der neue IPC-Vertrag fordert zwingend, dass unbekannte Kanäle im Preload blockiert werden, um die Angriffsfläche zu minimieren,. 2. Das „Envelope“-Pattern (Standardisierter Umschlag) Um die Kommunikation vorhersehbar zu machen, schreiben die Quellen vor, dass IPC-Antworten niemals „rohe“ Daten oder unstrukturierte Fehler sein dürfen. Stattdessen wird ein striktes „Result Envelope“ definiert,: • Struktur: Jede Antwort ist ein Objekt vom Typ IpcResult<T>, das entweder { ok: true, data: T } oder { ok: false, error: IpcError } enthält,. • Fehlerkultur: Fehler werden durch kanonische Codes (z. B. E_VALIDATION, E_WORKSPACE_REQUIRED) standardisiert, anstatt technische Stacktraces an das UI durchzureichen,. Dies ermöglicht dem Renderer, kindgerechte Fehlermeldungen (Toasts/Dialoge) anzuzeigen, ohne die interne Logik des Main-Prozesses verstehen zu müssen. 3. Definierte Kanäle und Datenfluss Der Vertrag legt eine feste Liste von Kanälen fest, die spezifische semantische Aufgaben erfüllen, anstatt generische Befehle zuzulassen,: • Persistenz (project:save/load): Diese Kanäle übertragen das Projekt-JSON. Der Vertrag schreibt vor, dass der Main-Prozess hierbei die „Workspace Sandbox“ erzwingen muss (Verwendung von safeJoin), um Path-Traversal-Angriffe zu verhindern,. Der Renderer darf nur relative Pfade oder das Datenobjekt senden, niemals absolute Zielpfade. • Pipeline (pipeline:start): Da Build-Vorgänge lange dauern, definiert der Vertrag diesen Kanal als asynchron. Er gibt sofort eine runId zurück, während der eigentliche Fortschritt über Push-Events (pipeline:progress) gemeldet wird,. • Hilfe (help:search): Ein dedizierter Kanal für die Offline-Suche in Markdown-Dateien, der Ergebnisse als typisierte HelpResult-Objekte zurückgibt. 4. Validierungs-Pflicht (Single Source of Truth) Ein wesentlicher Aspekt des IPC-Vertrags ist, dass der Main-Prozess (Empfänger) den Daten des Renderers (Sender) niemals blind vertrauen darf. • Validierung: Bevor Daten verarbeitet oder gespeichert werden, muss der Main-Prozess sie gegen das Schema des „Core Model“ validieren (validateProject). • Ablehnung: Ungültige Daten müssen mit einem E_VALIDATION-Fehler abgelehnt werden. Dies schützt das Dateisystem vor Korruption durch eine fehlerhafte UI. 5. Übertragbarkeit auf andere Systeme (Jarvis Kontext) Die Quellen zeigen, dass dieses Muster universell angewendet wird. Im „Jarvis“-System wird ein ähnlicher Vertrag genutzt, dort jedoch erweitert um „Event Envelopes“ (type, traceId, payload) und „Capability Tiers“ (z. B. read_only vs. destructive), um KI-Aktionen abzusichern,. Auch hier dient ein zentrales Manifest (event_catalog.json) als Vertrag, aus dem Code für Frontend (TypeScript) und Backend (Python) generiert wird, um „Drift“ zu vermeiden. Zusammenfassend ist die „IPC / Bridge Spec“ laut den Quellen das „Gesetzbuch“ der Anwendung. Es regelt nicht nur den Datentransport, sondern erzwingt Sicherheit (Sandboxing), Datenintegrität (Validierung) und Stabilität (Fehler-Envelopes), bevor die eigentliche Implementierung beginnt. Welche drei Komponenten umfasst die Build-Pipeline laut Architektur-Blueprint? Wie stellt das System Schutz vor Path-Traversal-Angriffen sicher? Warum gelten IDs laut der ID-Policy als immutable? Diskutieren, was diese Quellen im Kontext von „IPC / Bridge Spec“ über „IpcResult Envelope“ aussagen.  Basierend auf den vorliegenden Quellen wird der „IpcResult Envelope“ (oft auch als „Result Envelope“ oder „Umschlag-Muster“ bezeichnet) als ein unverzichtbarer architektonischer Vertrag (Contract) definiert. Er dient dazu, die Kommunikation zwischen dem unsicheren Frontend (Renderer/UI) und dem privilegierten Backend (Main-Process/Kernel) zu standardisieren, typsicher zu machen und von technischen Ausnahmen zu entkoppeln. Hier ist eine detaillierte Diskussion dessen, was die Quellen über dieses Konzept aussagen: 1. Definition und Struktur Der „IpcResult Envelope“ ist eine strikte Datenstruktur, die als Hülle für jede Antwort eines IPC-Aufrufs (Inter-Process Communication) dient. Anstatt rohe Daten zurückzugeben oder Exceptions zu werfen, gibt das Backend immer ein Objekt zurück, das explizit signalisiert, ob die Operation erfolgreich war oder nicht. Laut der IPC / Bridge Spec v1, besteht dieser Envelope aus einer „Discriminated Union“ (unterscheidbaren Vereinigung) in TypeScript: • Der Erfolgsfall (IpcOk<T>):     ◦ ok: true     ◦ data: T (Die angeforderten Daten, z. B. das Projekt-JSON oder eine Run-ID). • Der Fehlerfall (IpcFail):     ◦ ok: false     ◦ error: IpcError. Das IpcError-Objekt ist dabei ebenfalls standardisiert und enthält: • code: Ein kanonischer Fehlercode (z. B. E_VALIDATION, E_BUILD_FAILED),. • message: Eine benutzerfreundliche, kindgerechte Nachricht (z. B. "Dein Mod konnte nicht gebaut werden"). • details: Optionale technische Details (Logs, Stacktraces) für Entwickler, die im UI standardmäßig verborgen bleiben,. 2. Architektonische Ziele Die Einführung dieses Envelopes verfolgt laut den Quellen mehrere strategische Ziele im Rahmen des „Re-Assembly Plans“: • Entkopplung von Fehlern: Technische Fehler (wie Java-Exceptions im Exporter oder Dateisystem-Fehler) dürfen nicht ungefiltert bis ins UI durchschlagen. Der Envelope zwingt den Main-Process, diese Fehler abzufangen und in definierte Codes zu übersetzen,. • Typsicherheit: Durch die Definition in bridge.d.ts muss der Renderer den Fehlerfall explizit behandeln. Der Compiler zwingt den Entwickler zu prüfen: if (!result.ok) { showToast(result.error); return; }. • Vermeidung von „Raten“: Ohne Envelope müsste das UI oft raten, ob ein Rückgabewert null bedeutet, dass etwas nicht gefunden wurde oder ob ein Fehler auftrat. Der Envelope macht dies eindeutig (ok: true mit null-Daten vs. ok: false mit E_NOT_FOUND). 3. Anwendung in den Systemen Die Quellen zeigen, dass dieses Muster nicht nur für das „Minecraft Mod Studio“, sondern auch für das „Jarvis“-System als Best Practice gilt: • Minecraft Mod Studio (Electron): Hier wird der Envelope genutzt, um die asynchrone Kommunikation über die bridge.ts abzusichern. Kanäle wie project:save geben ein IpcResult zurück, das bestätigt, ob das atomare Schreiben im Sandbox-Workspace erfolgreich war,. • Jarvis Local Hub: Auch im „Skill Manifest“ dieses Systems wird ein resultEnvelope definiert,. Hier wird das Konzept sogar auf Python (Pydantic Models) ausgeweitet: class ResultOk und class ResultFail sorgen dafür, dass Backend und Frontend dieselbe Sprache sprechen. 4. Integration mit dem „Error Catalog“ Der Envelope ist das Transportmittel für den „Error Catalog“. Die Quellen betonen, dass der im Envelope enthaltene code aus einer festen Liste stammen muss (z. B. E_WORKSPACE_REQUIRED). Dies ermöglicht dem UI, spezifisch auf Fehler zu reagieren (z. B. Öffnen des Dateidialogs bei fehlendem Workspace), anstatt nur generische Fehlermeldungen anzuzeigen,. Zusammenfassung & Analogie Die Quellen beschreiben den „IpcResult Envelope“ als das „diplomatische Protokoll“ der Anwendung. Analogie: Wenn das UI (der Kunde) dem Main-Process (dem Bankangestellten) einen Auftrag gibt, ruft der Angestellte im Fehlerfall nicht einfach laut um Hilfe (Exception). Stattdessen füllt er ein standardisiertes Formular (den Envelope) aus. Er kreuzt entweder „Erledigt“ (ok: true) an und legt das Geld bei, oder er kreuzt „Abgelehnt“ (ok: false) an und schreibt einen verständlichen Grund dazu (message: „Unterschrift fehlt“), sowie eine Notiz für den Vorgesetzten (details: „Schema-Validierung fehlgeschlagen in Zeile 5“). Dies garantiert einen geordneten Betriebsablauf, selbst wenn im Hintergrund Chaos herrscht. Welche drei Hauptschichten bilden die Architektur der Electron-App? Wie verhindert das Modul workspace.ts Angriffe durch Path Traversal? Welche drei Prozessschritte umfasst die Build-Pipeline im BuildService? Diskutieren, was diese Quellen im Kontext von „IPC / Bridge Spec“ über „Kanäle: project:save/load“ aussagen.  Basierend auf den vorliegenden Quellen, insbesondere der „IPC / Bridge Spec v1“ und den Analyse-Reports zum „Minecraft Mod Studio for Kids“, definieren die Kanäle project:save und project:load den zentralen Vertrag für die Datenpersistenz. Die Quellen unterscheiden dabei scharf zwischen dem aktuellen, unfertigen Zustand (Prototyp) und der geforderten Spezifikation (Zielbild), die Sicherheit und Datenintegrität gewährleisten soll. Hier ist eine detaillierte Diskussion der Aussagen zu diesen Kanälen: 1. Status Quo: Vom "Stub" zur echten Implementierung Die Quellen identifizieren den aktuellen Code-Stand als kritischen Mangel. • Ist-Zustand: Im Main-Process (ipc.ts) sind diese Kanäle größtenteils als „Stubs“ (Platzhalter) implementiert. project:save gibt zwar ein success: true zurück, schreibt aber faktisch keine Daten auf die Festplatte. project:load ist oft als „not implemented“ markiert,. • Mock-Abhängigkeit: Um die Anwendung überhaupt demonstrieren zu können (insbesondere im Browser), nutzt der Renderer aktuell eine mockBridge in persistence.ts. Die Quellen warnen davor, dass dies Fehler maskiert, die erst in der echten Electron-Umgebung auftreten würden,. 2. Der Vertrag (Spec v1): Strikte Trennung und Sicherheit Die „IPC / Bridge Spec v1“ definiert für diese Kanäle einen harten Vertrag, der den Renderer als „untrusted“ (nicht vertrauenswürdig) und den Main-Process als Autorität einstuft. Kanal: project:save Dieser Kanal dient dem sicheren Schreiben des Projektzustands. • Request: Der Renderer sendet ein Objekt { workspaceDir: string, project: ProjectFile }. • Sicherheits-Logik (Main Process):     ◦ Sandbox: Der Pfad darf nicht vom Renderer frei gewählt werden. Der Main-Process muss zwingend safeJoin(workspaceDir, "project.json") verwenden. Dies verhindert „Path Traversal“-Angriffe (Ausbrechen aus dem Ordner),.     ◦ Validierung: Bevor geschrieben wird, muss das empfangene project-Objekt durch die Funktion validateProject (aus dem core-model) geprüft werden. Ungültige Daten führen zum Fehler E_VALIDATION,.     ◦ Atomares Schreiben: Um Datenverlust (z. B. bei Absturz während des Speicherns) zu verhindern, schreibt der Prozess zuerst in eine temporäre Datei und benennt diese dann um,. • Response: Ein standardisierter Envelope: { ok: true } oder { ok: false, error: IpcError }. Kanal: project:load Dieser Kanal dient dem Laden und Verifizieren eines bestehenden Projekts. • Request: Der Renderer sendet { workspaceDir: string }. • Logik:     ◦ Der Main-Process liest die Datei project.json aus dem Workspace (wiederum abgesichert durch safeJoin).     ◦ Validierung: Die geladene Datei wird gegen das Schema geprüft. Schlägt dies fehl, wird E_VALIDATION zurückgegeben; fehlt die Datei, wird E_NOT_FOUND gesendet,. • Response: { ok: true, project: ProjectFile } oder Fehler-Envelope. 3. Übergreifende Prinzipien für diese Kanäle Die Quellen heben hervor, dass project:save/load mehr sind als einfache Dateioperationen; sie fungieren als „Gatekeeper“ (Wächter) für das System. • Envelope-Pattern: Antworten erfolgen niemals als rohe Daten oder Exceptions, sondern immer verpackt in IpcResult<T>. Dies zwingt das UI dazu, Fehlercodes wie E_WORKSPACE_REQUIRED sauber zu behandeln und dem Nutzer (Kind) verständlich anzuzeigen (z. B. „Bitte wähle erst einen Ordner“),. • Single Source of Truth: Das Datenformat ist durch die „Project JSON Spec“ (Schema Version 1) festgeschrieben. Die IPC-Kanäle sind die Schnittstelle, die sicherstellt, dass nur valide Daten dieses Formats persistiert werden,. • Whitelist Enforcement: Im Preload-Skript (bridge.ts) muss technisch sichergestellt werden, dass nur diese explizit definierten Kanäle aufgerufen werden dürfen (VALID_CHANNELS), um die Angriffsfläche zu minimieren,. Zusammenfassung Die Quellen beschreiben project:save und project:load als die fundamentalen Bausteine der Phase 2 („Persistence & Sandbox“) im Wiederherstellungsplan (Re-Assembly Plan). Sie transformieren die Anwendung von einem Frontend-Demo-Prototypen in eine sichere Desktop-Software, indem sie Dateizugriffe streng validieren, kapseln (Sandboxing) und atomar ausführen,. Welche drei Phasen umfasst die Build-Pipeline im BuildService? Welche Sicherheitsmaßnahmen implementiert die workspace.ts gegen Path Traversal? Warum wird der Renderer architektonisch als „untrusted UI“ eingestuft? Diskutieren, was diese Quellen im Kontext von „IPC / Bridge Spec“ über „Kanäle: pipeline:start“ aussagen.  Basierend auf den vorliegenden Quellen, insbesondere der „IPC / Bridge Spec v1“ und der Analyse des „Main Process“, wird der Kanal pipeline:start als der zentrale Auslöser für die Kernfunktionalität der Anwendung definiert: die Umwandlung eines Daten-Projekts in einen spielbaren Minecraft-Mod. Die Quellen beschreiben diesen Kanal nicht als einfache Funktion, sondern als Startpunkt eines asynchronen Zustandsautomaten. Hier ist die detaillierte Diskussion der Aussagen: 1. Der Vertrag (Contract): Asynchrone Initiierung Im Gegensatz zu synchronen Operationen (wie dialog:selectWorkspace), bei denen das Ergebnis sofort zurückkommt, definiert die Spezifikation pipeline:start als „Fire-and-Forget“-Mechanismus mit einer Rückverfolgbarkeit. • Request: Der Renderer sendet das gesamte ProjectFile an den Main-Prozess: { "project": { ... } },. • Response: Der Main-Prozess blockiert das UI nicht bis der Build fertig ist. Stattdessen antwortet er sofort mit einer runId (z. B. einer UUID oder einem Zeitstempel) in einem Erfolgs-Envelope: { "ok": true, "runId": "..." },. • Zweck: Die runId dient als Referenzticket. Das UI weiß nun, dass der Auftrag angenommen wurde, kennt aber das Ergebnis noch nicht. 2. Die Rückkopplung: Der pipeline:progress Event-Strom Da der Build-Prozess (Gradle, Server-Start) Zeit in Anspruch nimmt (laut testbot z. B. bis zu 3 Minuten Timeout), beschreiben die Quellen einen gekoppelten Push-Event-Kanal. • Event: Der Main-Prozess sendet kontinuierlich Events auf dem Kanal pipeline:progress an den Renderer. • Payload: Das Event enthält die runId (zur Zuordnung) und ein PipelineStatus-Objekt:     ◦ step: Der aktuelle Schritt (export, build, test, done, error),.     ◦ message: Eine kindgerechte Nachricht (z. B. "Building your mod...").     ◦ details: Optionale technische Details für Entwickler. • UI-Integration: Das Frontend (BuildDialog.tsx) abonniert diesen Kanal. Es nutzt die Events, um einen Fortschrittsbalken („Stepper“) zu aktualisieren, der niemals in einem undefinierten Zustand verharren darf,. 3. Die Orchestrierung im Main-Process (buildService.ts) Der Kanal pipeline:start ist der direkte Auslöser für den buildService. Die Quellen betonen, dass dieser Service keine Geschäftslogik berechnet, sondern externe Werkzeuge dirigiert: 1. Validierung: Bevor irgendetwas passiert, muss der Handler das empfangene Projekt mittels validateProject prüfen. Ist es ungültig, wird sofort mit E_VALIDATION abgebrochen, noch bevor eine runId erzeugt wird. 2. Ablauf: Der Service arbeitet die Schritte sequenziell ab:     ◦ export: Aufruf von @kidmodstudio/exporter in ein temporäres Verzeichnis,.     ◦ build: Starten des Gradle-Prozesses via Exporter,.     ◦ test: Ausführen des @kidmodstudio/testbot (runServer),. 3. Concurrency: Die Spec sieht vor, dass der Main-Prozess prüft, ob bereits eine Pipeline läuft. Falls ja, wird der Start mit dem Fehlercode E_PIPELINE_RUNNING abgelehnt, um Ressourcenkonflikte zu vermeiden,. 4. Fehlerbehandlung und Abbruch Die Quellen definieren spezifische Fehlerzustände für diesen Kanal, die über das Standard-Envelope kommuniziert werden: • Fehler-Mapping: Wenn ein Schritt fehlschlägt (z. B. Gradle Exit Code != 0), wird der Status auf error gesetzt und ein passender Code gesendet (z. B. E_BUILD_FAILED oder E_TEST_FAILED),. • Cancel-Option: Die Spec erwähnt pipeline:cancel als optionalen, aber empfohlenen Kanal. Da pipeline:start Kindprozesse (Gradle, Java) startet, muss der Main-Prozess die Prozess-Handles (PIDs) speichern, um sie bei einem Abbruch durch den Nutzer sauber zu beenden,. Zusammenfassung Die Quellen beschreiben pipeline:start als den komplexesten IPC-Kanal der Anwendung. Er ist die Schnittstelle zwischen der synchronen Welt des UI und der langwierigen, prozesslastigen Welt des Compilers. Analogie: Man kann sich pipeline:start wie die Abgabe von Kleidung in einer Reinigung vorstellen. 1. Abgabe (start): Der Kunde (Renderer) gibt das Kleidungsstück (Projekt) ab. Der Mitarbeiter (Main-Prozess) prüft kurz, ob die Taschen leer sind (Validierung). 2. Abholschein (runId): Der Kunde erhält sofort einen Abholschein mit einer Nummer. Er wartet nicht am Tresen, bis die Wäsche gewaschen ist. 3. Status-Display (progress): Ein Bildschirm im Laden zeigt an: „Auftrag 123: Wird gewaschen... Wird gebügelt... Fertig“. 4. Fehler (E_BUILD_FAILED): Wenn die Maschine kaputt geht, erscheint auf dem Display: „Auftrag 123: Problem aufgetreten“, anstatt dass der Mitarbeiter einfach verschwindet. Welche drei Komponenten umfasst die Build-Pipeline laut „buildService.ts“? Wie schützt die Funktion `safeJoin` das System vor Path-Traversal-Angriffen? Warum wird für Projekt-IDs die „Immutable ID Policy“ empfohlen? Diskutieren, was diese Quellen im Kontext von „Zentrale Verträge (Contracts)“ über „Error Catalog“ aussagen.  Die Analyse der Quellen zeigt, dass der „Error Catalog“ (Fehlerkatalog) im Kontext der „Zentralen Verträge“ eine entscheidende Rolle für die Stabilität und Benutzerfreundlichkeit des „Minecraft Mod Studio for Kids“ spielt. Er ist nicht bloß eine Liste von Fehlermeldungen, sondern ein verbindliches architektonisches Protokoll, das die Kommunikation von Fehlern zwischen dem Backend (Main Process/Exporter) und dem Frontend (Renderer UI) standardisiert. Hier ist eine detaillierte Diskussion der Aussagen der Quellen zu diesem Vertrag: 1. Definition und Zielsetzung: Das „Error Envelope“ Der Error Catalog definiert ein striktes JSON-Format, den sogenannten „Umschlag“ (Envelope), für alle fehlgeschlagenen IPC-Operationen. Anstatt rohe Exceptions oder Stack-Traces zu werfen, muss jede Antwort bei einem Fehler folgender Struktur entsprechen: • Format: { ok: false, error: { code, message, details? } },. • Ziel: Dies entkoppelt die UI von der technischen Implementierung. Der Renderer muss nicht wissen, warum Gradle abgestürzt ist (z. B. fehlende Java-Version), er muss nur den Code (E_BUILD_FAILED) erkennen, um den richtigen UI-Zustand anzuzeigen. 2. Kanonische Fehlercodes (Die „Stable Codes“) Die Quellen legen eine feste, unveränderliche Liste von Fehlercodes fest. Diese Codes bleiben stabil, selbst wenn sich die zugrunde liegende Technik ändert. Die wichtigsten definierten Codes sind: • E_VALIDATION: Der wichtigste Code für die Datenintegrität. Er wird geworfen, wenn das Datenmodell (z. B. validateProject) Schema- oder Semantikfehler meldet (z. B. „Rezept verweist auf fehlendes Item“),. • E_WORKSPACE_REQUIRED: Verhindert Operationen, bevor ein Arbeitsordner gewählt wurde. Die UI soll daraufhin proaktiv den Ordner-Dialog öffnen,. • E_PATH_TRAVERSAL: Ein Sicherheits-Code, der ausgelöst wird, wenn versucht wird, aus der „Sandbox“ auszubrechen (z. B. durch Pfade mit ../),. • E_BUILD_FAILED: Spezifisch für die Pipeline. Er signalisiert, dass der Export oder der Gradle-Build fehlgeschlagen ist (z. B. Exit Code != 0),. • E_TEST_FAILED: Der Build war erfolgreich, aber der Test-Server ist abgestürzt oder in ein Timeout gelaufen,. 3. UX-Philosophie: Kindgerechte Kommunikation Ein zentraler Aspekt des Error Catalogs ist die strikte Trennung zwischen technischer Diagnose und Nutzerkommunikation. Die Quellen schreiben vor, dass die message im Fehlerobjekt kindgerecht und handlungsorientiert sein muss: • Verbot von Jargon: Technische Begriffe wie „Exception“, „Exit Code“ oder „IO Error“ dürfen in der message nicht vorkommen. • Lösungsorientierung:     ◦ Statt „Permission Denied“ (E_IO) heißt es: „Ich kann gerade keine Dateien lesen oder schreiben.“,.     ◦ Statt „Gradle Build Failed“ (E_BUILD_FAILED) heißt es: „Dein Mod konnte nicht gebaut werden. Lass uns das reparieren!“,. • Entschärfung: Die Nutzung von Wörtern wie „Oops!“ oder „Uh oh“ soll Fehler weniger bedrohlich wirken lassen,. 4. Technische Details für Entwickler (details) Um die Debugging-Fähigkeit nicht zu verlieren, definiert der Vertrag ein optionales Feld details. • Inhalt: Hier landen die rohen Logs, Stack-Traces oder spezifische JSON-Pfade (z. B. /recipes/r1/key/R bei Validierungsfehlern),. • UI-Regel: Diese Details dürfen niemals standardmäßig angezeigt werden. Sie müssen hinter einem „Show details“-Expander versteckt sein, der für Eltern oder Mentoren gedacht ist,. 5. Mapping-Regeln Der Vertrag legt fest, welches technische Ereignis zu welchem Code führt. Dies verhindert „String-Typing“ (das Erraten von Fehlern anhand von Log-Texten) im Frontend: • Ein JSON.parse Fehler beim Laden wird zwingend zu E_VALIDATION (Nachricht: „Saved file looks broken“). • Ein Timeout des Test-Servers wird zu E_TEST_FAILED. • Das Fehlen der project.json wird zu E_NOT_FOUND. Zusammenfassende Analogie Die Quellen beschreiben den Error Catalog implizit als einen Diplomaten. Wenn im Maschinenraum (Main Process/Build Tools) Chaos ausbricht (Feuer, Explosionen, unverständliche Java-Fehler), rennt der Diplomat nicht schreiend zum Kind (Renderer UI). Stattdessen übersetzt er die Katastrophe in eine ruhige, standardisierte Nachricht („Wir haben ein kleines technisches Problem, Code: E_BUILD_FAILED“) und reicht dem Kind einen konstruktiven Vorschlag („Lass uns das reparieren!“), während er den detaillierten Unfallbericht (details) in einem versiegelten Umschlag für die Experten bereithält,. Welche drei Komponenten umfasst die Build-Pipeline im BuildService? Welche Sicherheitsmaßnahmen implementiert die workspace.ts gegen Path Traversal? Warum wird die Verwendung von „immutable IDs“ im Projekt empfohlen? Diskutieren, was diese Quellen im Kontext von „Error Catalog“ über „User-Messages: Kindgerechte Texte“ aussagen.  Basierend auf den vorliegenden Quellen, insbesondere dem „Error Catalog v1“ (Entwurf) und den Diskussionen über die UX-Philosophie des Projekts, spielen „User-Messages: Kindgerechte Texte“ eine entscheidende Rolle. Die Quellen definieren Fehlerbehandlung nicht als technisches Logging, sondern als pädagogisches Werkzeug, um Frustration bei der Zielgruppe (Kinder) zu vermeiden. Hier ist eine detaillierte Diskussion der Aussagen: 1. Das Grundprinzip: Übersetzung statt Konfrontation Der „Error Catalog“ legt als oberste Regel fest: „Always show a short, friendly message“ (Zeige immer eine kurze, freundliche Nachricht) und verbietet standardmäßig die Anzeige von „raw stack traces“ (rohen Fehlerprotokollen),. • Technik-Abstraktion: Die Quellen fordern, dass technische Begriffe wie „Gradle“, „Schema Validation“, „Exit Code“ oder „IO Exception“ vollständig aus der Benutzeroberfläche verbannt werden. • Atmosphäre: Die Sprache soll entschärfend wirken. Wörter wie „Oops!“ oder „Uh oh“ werden empfohlen, um Fehler weniger bedrohlich erscheinen zu lassen,,. 2. Die Architektur der Nachricht (Trennung der Ebenen) Die Quellen beschreiben eine klare Trennung im Datenmodell des Fehlers (Error Envelope), um verschiedene Zielgruppen zu bedienen,: • message (Für das Kind): Ein einfacher, handlungsorientierter Satz. • details (Für Eltern/Entwickler): Hier landen die technischen Logs und Pfade, die jedoch in der UI hinter einem „Show details“-Expander versteckt werden müssen. 3. Konkrete Beispiele für „Kindgerechte Texte“ Die Quellen liefern spezifische Mappings, wie technische Fehlercodes (z. B. E_VALIDATION) in kindgerechte Sprache übersetzt werden sollen. Hierbei werden sowohl englische Vorlagen als auch explizite deutsche Übersetzungen genannt: • Bei Validierungsfehlern (E_VALIDATION):     ◦ Technisch: Schema-Verletzung oder ungültige Referenz.     ◦ Kindgerecht (EN): „Oops! One part of your mod does not make sense yet.“.     ◦ Kindgerecht (DE): „In deinem Mod stimmt etwas noch nicht. Bitte repariere es und versuch es nochmal.“.     ◦ Ziel: Das Kind soll verstehen, dass etwas am Mod korrigiert werden muss, ohne sich durch Begriffe wie „Illegal Argument“ angegriffen zu fühlen. • Bei Build-Fehlern (E_BUILD_FAILED):     ◦ Technisch: Gradle Exit Code != 0.     ◦ Kindgerecht (EN): „Your mod did not build. Let's fix it!“.     ◦ Kindgerecht (DE): „Dein Mod konnte nicht gebaut werden. Lass uns das reparieren!“.     ◦ Ziel: Die Formulierung „Let's“ (Lass uns) suggeriert eine gemeinsame Problemlösung durch das System und das Kind, anstatt das Kind mit dem Scheitern allein zu lassen. • Bei fehlendem Arbeitsordner (E_WORKSPACE_REQUIRED):     ◦ Technisch: Workspace Path is null.     ◦ Kindgerecht (DE): „Bitte wähle zuerst einen Ordner, damit ich weiss, wo ich speichern soll!“.     ◦ Ziel: Eine klare Handlungsanweisung statt einer Fehlermeldung. • Bei Systemfehlern (E_IO, E_UNKNOWN):     ◦ Kindgerecht (DE): „Ich kann gerade keine Dateien lesen oder schreiben.“ (statt „Permission Denied“).     ◦ Kindgerecht (DE): „Da ist etwas Unerwartetes passiert.“. 4. Integration in den „Creeper-Flavor“ Die Quellen erwähnen am Rande, dass diese Texte Teil einer umfassenderen UX-Strategie sind, die auch im Modul explain.ts (für Erfolgsmeldungen) Anwendung findet. Dort ist von einem „Creeper-Flavor“ die Rede. Das deutet darauf hin, dass die Texte nicht nur verständlich, sondern auch thematisch in die Minecraft-Welt eingebettet sein sollen, um die Immersion aufrechtzuerhalten (der Assistent als „Buddy“). Zusammenfassung Die Quellen sagen aus, dass der „Error Catalog“ weit mehr ist als eine Liste technischer Codes. Er ist ein UX-Vertrag, der sicherstellt, dass das System niemals „die Maske fallen lässt“. Analogie: Das System agiert wie ein freundlicher Dolmetscher. Wenn im Maschinenraum (Backend) ein Mechaniker schreit „Die Hydraulikleitung an Index 4 ist geplatzt!“ (Exception), übersetzt der Dolmetscher (Error Catalog) dies für das Kind im Cockpit ruhig mit: „Hoppla, an dieser Stelle klemmt etwas. Lass uns das reparieren!“