Architektur-Blueprint: Minecraft Mod Studio for Kids 9 Quellen Heute • 05:40 Diskutieren, was diese Quellen im Kontext von „Minecraft Mod Studio for Kids (Repo-Analyse)“ über „Zentrale Verträge (Contracts)“ aussagen.  Die Analyse der bereitgestellten Quellen zum „Minecraft Mod Studio for Kids“ zeigt, dass „Zentrale Verträge“ (Contracts) das fundamentale architektonische Mittel sind, um das Repository von einem unfertigen Prototypen (mit Platzhaltern wie ...) in ein stabiles, sicheres und erweiterbares System zu verwandeln. Die Quellen definieren explizit eine „Contract-First“-Strategie, bei der Schnittstellen fixiert werden, bevor die Implementierung finalisiert wird. Hier ist eine detaillierte Diskussion der drei zentralen Verträge und ihrer Bedeutung laut den Quellen: 1. Der Daten-Vertrag: Project JSON Spec v1 Dieser Vertrag dient als „Single Source of Truth“ für das gesamte System. Er definiert, wie ein Mod-Projekt gespeichert wird, und entkoppelt das UI von der Logik. • Zweck: Ein einziges Dateiformat (project.json) ermöglicht Speichern, Laden, Undo/Redo und den Export. Es muss streng validierbar sein, um sicherzustellen, dass keine korrupten Daten in den Build-Prozess gelangen. • Struktur:     ◦ Versionierung: Das Feld schemaVersion: 1 ist zwingend, um zukünftige Migrationen zu ermöglichen.     ◦ Identitäten: Es werden strikte Regex-Regeln für IDs definiert (z. B. ^[a-z0-9_]+$), um Kompatibilität mit Minecraft/Fabric zu garantieren.     ◦ Texturen: Eine kanonische Definition (TextureSpec) unterscheidet zwischen Presets (z. B. "rock") und DataURIs (Base64 PNGs), um den Export deterministisch zu machen. • Kritische Entscheidung (ID-Policy): Die Quellen diskutieren intensiv das Problem von umbenannten IDs. Die Empfehlung lautet, IDs nach der Erstellung unveränderlich (immutable) zu machen. Eine Umbenennung wird technisch als „Kopie mit neuer ID + Löschen der alten“ gelöst, um Referenzfehler in Rezepten zu vermeiden. 2. Der Kommunikations-Vertrag: IPC / Bridge Spec v1 Dieser Vertrag regelt die Interaktion zwischen dem unsicheren UI (Renderer/React) und dem privilegierten Hauptprozess (Electron/Main), der Zugriff auf das Dateisystem hat. • Sicherheits-Grenze (Trust Boundary): Der Renderer darf niemals direkten Zugriff auf Dateisystem-Operationen haben. Stattdessen nutzt er eine window.KidMod-API, die über eine contextBridge bereitgestellt wird. • Kanonische Kanäle: Die Kommunikation ist auf eine „Allowlist“ von Kanälen beschränkt, wie z. B. project:save, project:load oder pipeline:start. • Envelope-Pattern (Umschlag): Antworten folgen einem strikten Schema (IpcResult), das entweder { ok: true, data: ... } oder { ok: false, error: ... } zurückgibt. Dies verhindert, dass technische Fehler (Stacktraces) ungefiltert im UI landen. • Sandbox-Zwang: Der Main-Prozess muss bei jedem Dateizugriff safeJoin(workspaceDir, ...) verwenden, um „Path Traversal“-Angriffe (Ausbrechen aus dem Ordner) zu verhindern. 3. Der Output-Vertrag: Exporter Manifest v1 Dieser Vertrag stellt sicher, dass der Export-Prozess deterministisch ist, also bei gleicher Eingabe immer exakt dieselbe Dateistruktur erzeugt. • Ziel: Der Exporter erzeugt ein vollständig baufertiges Fabric-Mod-Projekt (Gradle), das Assets, Code und Konfigurationen enthält. • Struktur-Garantie: Das Manifest legt fest, wo genau Dateien liegen müssen (z. B. src/main/resources/assets/<modId>/textures/...), damit der Minecraft-Build-Prozess funktioniert. • Generierung:     ◦ Platzhalter im Template (z. B. {{MOD_ID}}) werden durch Metadaten aus der project.json ersetzt.     ◦ Java-Code (ModRegistry.java) und JSON-Assets (Blockstates, Models) werden maschinell und fehlerfrei aus dem Datenmodell abgeleitet. 4. Der UX-Vertrag: Error Catalog & Pipeline Status Zusätzlich zu den technischen Schnittstellen definieren die Quellen Verträge für das Nutzererlebnis, insbesondere im Fehlerfall. • Error Catalog: Es wird eine standardisierte Liste von Fehlercodes definiert (z. B. E_VALIDATION, E_BUILD_FAILED), die mit kindgerechten Nachrichten verknüpft sind. Ein Fehler beim Speichern wird beispielsweise nicht als „EACCES“ angezeigt, sondern als „Ich kann gerade keine Dateien lesen oder schreiben“. • Pipeline Status: Der Build-Prozess (Export -> Build -> Test) kommuniziert über definierte Schritte (export, build, test, done, error) via Push-Events an das UI, sodass der Fortschrittsbalken („Stepper“) immer synchron ist. Zusammenfassung der Strategie Die Quellen argumentieren, dass diese Verträge die Voraussetzung für eine erfolgreiche Rekonstruktion („Assembly“) des Repositories sind: 1. Phase 1 (Core Truth): Zuerst wird das Datenmodell (core-model) gemäß der Project JSON Spec stabilisiert und von Platzhaltern bereinigt. 2. Phase 2 (Sicherheit): Dann wird die IPC-Schicht gemäß der Bridge Spec implementiert, um Speichern/Laden sicher zu machen. 3. Phase 3 (Zuverlässigkeit): Zuletzt wird der Exporter so umgebaut, dass er strikt das Manifest erfüllt. Analogie: Die Verträge fungieren wie der Bauplan und die Hausordnung beim Hausbau. Die Project JSON Spec ist der Grundriss (was wird gebaut?), die Bridge Spec sind die Sicherheitsvorschriften (wer darf wo arbeiten?), und das Exporter Manifest ist das Abnahmeprotokoll (wann ist das Haus fertig und sicher bewohnbar?). Ohne diese Verträge bleibt das Projekt eine instabile Baustelle. Welche drei Hauptschichten bilden die Architektur der Desktop-App? Welche Aufgaben übernimmt der `testbot` innerhalb der Build-Pipeline? Wie unterscheiden sich die Textur-Quellen `preset` und `dataUri`? Diskutieren, was diese Quellen im Kontext von „Zentrale Verträge (Contracts)“ über „Project JSON Spec“ aussagen.  Die Quellen definieren die „Project JSON Spec“ (spezifisch Version 1) als das wichtigste Fundament im gesamten „Minecraft Mod Studio for Kids“-System. Sie fungiert als die „Single Source of Truth“ (einzige Wahrheitsquelle), die alle Systemkomponenten – vom UI-Renderer über die Speicherlogik bis hin zum Exporter – entkoppelt und synchronisiert,. Hier ist eine detaillierte Diskussion dessen, was die Quellen über diesen Vertrag aussagen: 1. Kernfunktion und Zielsetzung Die „Project JSON Spec“ (dokumentiert in docs/contracts/project-json-spec-v1.md) dient dazu, ein einziges, kanonisches Dateiformat (project.json) festzulegen, das für folgende Mechanismen verantwortlich ist: • Persistenz: Speichern und Laden (Save/Load) des Projektzustands im Workspace. • Statusverwaltung: Basis für Undo/Redo-Operationen im Domain-State. • Export: Dient als deterministische Eingabe für den Exporter, der daraus den Fabric-Mod-Code generiert. • Testing: Ermöglicht automatisierte "Smoke Tests" der Build-Pipeline. Das Ziel ist ein Format, das kindgerecht editierbar, aber technisch streng validierbar ist, um Fehler frühzeitig abzufangen, bevor komplizierte Java-Build-Fehler entstehen. 2. Struktur der Spezifikation (v1) Der Vertrag legt eine strikte JSON-Struktur fest, die im core-model mittels Zod implementiert wird,. • Versionierung: Das Feld schemaVersion: 1 ist zwingend. Unbekannte Versionen müssen abgelehnt oder migriert werden. • Metadaten (meta): Enthält essenzielle Projektinfos wie modId, name, version, author und Zeitstempel. • Container: Die Datenhaltung erfolgt in drei Hauptkategorien, die als Records (Key-Value-Paare) organisiert sind, wobei der Key der ID entspricht:     ◦ blocks: Definition von Blöcken.     ◦ items: Definition von Gegenständen.     ◦ recipes: Definition von Crafting-Rezepten. 3. Zentrale Design-Regeln und Datentypen Die Quellen heben spezifische Regeln hervor, die diesen Vertrag robust machen: A. Naming und IDs Es gelten strenge Regex-Regeln, um Kompatibilität mit Minecraft/Fabric zu sichern: • EntityId: Kleinbuchstaben, Zahlen, Unterstriche (^[a-z0-9_]+$). Beispiele: ruby_block, shiny_gem. • ModId: Muss mit einem Buchstaben beginnen (^[a-z][a-z0-9_]{1,63}$) und dient als Namespace für alle Inhalte,. B. Texturen (TextureSpec) Um die Lücke zwischen UI (Vorschau) und Export (Dateisystem) zu schließen, definiert der Vertrag zwei zulässige Textur-Quellen: 1. Preset: Ein Verweis auf eine interne Vorlage (z. B. value: "rock"). 2. DataUri: Ein Base64-kodiertes PNG (data:image/png;base64,...). Empfehlung: Für maximale Determinismus im Export wird empfohlen, Texturen im UI immer als dataUri zu speichern, auch wenn sie aus Presets stammen. C. Referenzen (NamespacedRef) Referenzen (z. B. in Rezepten) müssen entweder auf minecraft:* (Vanilla-Items) oder auf Objekte innerhalb der eigenen ModId (modId:*) verweisen. 4. Semantische Validierung Der Vertrag schreibt vor, dass die Datei nicht nur strukturell (Schema), sondern auch semantisch validiert werden muss (validateProject), bevor sie gespeichert oder exportiert wird,. Zu den Regeln gehören: • Der Key im JSON-Objekt muss exakt der id im Objekt entsprechen. • Referenzen in Rezepten (Keys und Result) müssen auf tatsächlich existierende Items oder Blöcke zeigen. • Texturen müssen gültige PNG-Daten oder erlaubte Presets sein. 5. ID-Richtlinie (Immutable vs. Rename) Die Quellen diskutieren ein kritisches Risiko bei der Änderung von IDs. Da IDs als Referenzschlüssel dienen, führt eine Umbenennung zu gebrochenen Verknüpfungen (z. B. in Rezepten). • Empfehlung: Die „Project JSON Spec“ empfiehlt, IDs nach der Erstellung als immutable (unveränderlich) zu behandeln. • Lösung: Statt Umbenennen soll das UI eine „Kopieren als neue ID + Löschen der alten ID“-Logik anbieten, um Komplexität im reducer zu vermeiden,. Zusammenfassung Im Kontext der „Zentralen Verträge“ ist die Project JSON Spec das Herzstück der Architektur. Sie ermöglicht es, das core-model als 100% saubere Wahrheit zu stabilisieren. Alle anderen Komponenten (Renderer, Exporter, Main-Process) sind lediglich Adapter, die Daten basierend auf diesem Vertrag lesen oder schreiben. Ohne die Stabilisierung dieses Vertrags ist ein verlässliches „Zusammensetzen“ der Mod-Studio-Komponenten laut den Quellen nicht möglich,. Welche konkreten Zod-Schemas definiert die „Project JSON Spec v1“? Wie sieht die „ID Rename Policy“ für das Projektformat aus? Welche IPC-Kanäle regeln die Kommunikation zwischen Renderer und Main-Prozess? Diskutieren, was diese Quellen im Kontext von „Project JSON Spec“ über „schemaVersion: 1“ aussagen.  Basierend auf den vorliegenden Quellen, insbesondere den Planungsdokumenten („Contracts“) und den Implementierungs-Patches für das „Minecraft Mod Studio for Kids“, hat das Feld „schemaVersion: 1“ eine zentrale Funktion als Stabilitätsanker und Versionierungsinstrument für das Projektdateiformat (project.json). Hier ist eine detaillierte Analyse, was die Quellen über dieses spezifische Feld aussagen: 1. Definition als fundamentale Konstante Im Kontext der „Project JSON Spec v1“ wird schemaVersion: 1 als zwingendes Top-Level-Feld in der Projektdatei definiert,. Es dient dazu, das Dateiformat eindeutig zu identifizieren und von zukünftigen, potenziell inkompatiblen Versionen zu unterscheiden. • Single Source of Truth: Die Quellen betonen, dass die Projektdatei (project.json) mit dieser Versionierung die einzige Wahrheit für Speichern/Laden, Export und Undo/Redo darstellt. • Festgelegter Wert: In der aktuellen Spezifikation ist der Wert fest auf die Zahl 1 (Integer) gesetzt. 2. Technische Implementierung via Zod In den Code-Patches für das core-model wird schemaVersion nicht als beliebige Zahl, sondern als strenges Literal implementiert. Das bedeutet, der Parser akzeptiert nur exakt den Wert 1. • Zod-Schema: Der Quellcode definiert das Schema wie folgt: • Dies stellt sicher, dass jede Datei, die keine 1 enthält (oder das Feld ganz missen lässt), sofort als ungültig abgelehnt wird. 3. Validierungsregeln und Sicherheit Die Quellen legen strikte Regeln für den Umgang mit diesem Feld fest, um die Datenintegrität zu gewährleisten: • Ablehnung unbekannter Versionen: Die Validierungslogik (validateProject) muss prüfen, ob die schemaVersion bekannt ist. Wenn eine unbekannte Version (z. B. 2 oder 0) gefunden wird, muss die Datei abgelehnt werden. • Schutz vor Datenkorruption: Durch diese Prüfung wird verhindert, dass der Editor versucht, eine Datei zu laden, deren Struktur er nicht versteht, was zu Abstürzen oder Datenverlust führen könnte. 4. Migrationsstrategie (Zukunftssicherheit) Die Quellen diskutieren schemaVersion: 1 explizit als Vorbereitung für zukünftige Änderungen am Datenformat. • Migrationspfad: Sollte ein „v2“-Format erscheinen, dient dieses Feld als Trigger für eine Migrationsfunktion (migrate(project: any): ProjectFileV2), die im core-model implementiert werden würde. • Exporter-Kompatibilität: Der Exporter (der den Minecraft-Mod baut) darf nur die aktuellste Version akzeptieren oder muss sicherstellen, dass vorher eine Migration stattgefunden hat. 5. Kontext innerhalb der JSON-Struktur In der vollständigen Struktur der project.json steht schemaVersion an oberster Stelle, noch vor den Metadaten. Ein valides Beispiel laut Spec v1 sieht so aus: {   "schemaVersion": 1,   "meta": {     "modId": "kid_ruby_mod",     "name": "Ruby Mod",     "version": "0.1.0",     ...   },   "blocks": { ... },   "items": { ... },   "recipes": { ... } } , Zusammenfassung Im Kontext des „Project JSON Spec“ ist „schemaVersion: 1“ nicht nur eine Versionsnummer, sondern ein harter technischer Vertrag (Contract). Er wird durch das Typsystem (z.literal(1)) erzwungen, dient als erster Gatekeeper bei der Validierung und bildet das Fundament für eine sichere Weiterentwicklung (Migration) der Software, ohne alte Projekte unbrauchbar zu machen. Welche drei Komponenten umfasst die Build-Pipeline im Architektur-Blueprint? Welche harten Regeln gelten für die Formatierung von Entity-IDs? Wie unterscheiden sich die Textur-Quellen „preset“ und „dataUri“ technisch? Diskutieren, was diese Quellen im Kontext von „Project JSON Spec“ über „meta: modId, name, version“ aussagen.  Basierend auf den Quellen, insbesondere den Entwurfsdokumenten („Project JSON Spec v1“, „Exporter Manifest“) und den Refactoring-Plänen, spielen die Felder meta: modId, name, version eine zentrale, infrastrukturelle Rolle im „Minecraft Mod Studio for Kids“. Sie sind nicht nur beschreibende Metadaten, sondern definieren die technische Identität und die Build-Logik des Mods. Hier ist eine detaillierte Diskussion der Aussagen der Quellen zu diesen Feldern: 1. Definition und Struktur („Single Source of Truth“) Im Kontext der Project JSON Spec v1 ist das meta-Objekt der unveränderliche Kern eines Projekts. Die Quellen definieren exakte Schemata und Validierungsregeln, um sicherzustellen, dass das Projekt technisch funktionsfähig bleibt. • Pflichtfelder: Die Felder modId, name und version sind zwingend erforderlich,. • Zusätzliche Felder: Es gibt optionale Felder wie author, description sowie Zeitstempel (createdAt, updatedAt), die für die Anzeige oder Dokumentation genutzt werden,. • Validierung (Schema): Der Refactoring-Plan legt spezifische „Zod“-Schema-Regeln fest:     ◦ modId: Muss strengen Regex-Regeln folgen (^[a-z][a-z0-9_]{1,63}$). Sie muss mit einem Buchstaben beginnen, darf nur Kleinbuchstaben, Ziffern und Unterstriche enthalten und maximal 63 Zeichen lang sein,.     ◦ name: Ein String zwischen 1 und 50 Zeichen.     ◦ version: Ein String zwischen 1 und 20 Zeichen (SemVer wird empfohlen),. 2. Die modId als technischer Anker (Namespace) Die Quellen betonen, dass die modId weit mehr ist als nur eine ID; sie ist die Basis für den Namespace des gesamten Mods. • Ressourcen-Referenzierung: Alle im Projekt erstellten Blöcke, Items und Rezepte werden intern über Namespaces referenziert. Die meta.modId bildet hierbei das Präfix. Wenn die modId beispielsweise kid_ruby_mod lautet, wird ein Block intern als kid_ruby_mod:ruby_block angesprochen. • Invarianten: Es gilt die Regel, dass Referenzen innerhalb von Rezepten entweder auf minecraft:* (Vanilla-Items) oder auf <modId>:* (eigene Items) zeigen müssen. Die Validierungslogik (validate.ts) prüft explizit, ob Referenzen zur meta.modId passen. 3. Rolle im Export- und Build-Prozess (Exporter Manifest) Im Kontext des Exporter Manifest v1 steuern diese Metadaten die Generierung des physischen Fabric-Mod-Codes. Der Exporter fungiert als Übersetzer, der die JSON-Daten in Java- und Gradle-Dateien schreibt. • Platzhalter-Ersetzung: Im Template-Ordner (packages/exporter/template) existieren Dateien mit Platzhaltern, die durch die meta-Werte ersetzt werden:     ◦ {{MOD_ID}} → project.meta.modId     ◦ {{MOD_NAME}} → project.meta.name     ◦ {{MOD_VERSION}} → project.meta.version • Java-Paketierung: Die modId bestimmt deterministisch den Java-Paketpfad und die Klassennamen, um Namenskonflikte zu vermeiden.     ◦ Das Paket wird zu com.kidmodstudio.<modId>.     ◦ Die Hauptklasse (Main Class) wird aus der modId in PascalCase umgewandelt (z. B. wird aus kid_ruby_mod → KidRubyMod.java). • Konfigurationsdateien: Die Datei fabric.mod.json (die Metadaten für den Fabric Loader) und die Mixin-Konfiguration (<modId>.mixins.json) werden direkt mit diesen Werten befüllt. 4. Refactoring und Stabilisierung Die Quellen zeigen, dass die Handhabung dieser Daten im ursprünglichen Code teilweise durch Platzhalter („Stubs“) oder unvollständige Implementierungen geprägt war. Der Assembly Plan und Patch Plan priorisieren daher die Formalisierung dieser Felder: • Es wurde festgelegt, dass meta Teil des „Core Model“ ist, welches als erstes stabilisiert werden muss (Phase 1), bevor an UI oder Export gearbeitet wird. • Die Validierung dieser Felder geschieht nun zentral im core-model und nicht mehr verstreut in der UI oder im Exporter, um eine „Single Source of Truth“ zu garantieren. Zusammenfassung Im Kontext der „Project JSON Spec“ sind modId, name und version die fundamentalen Konfigurationsdaten. Während name und version vor allem für die Anzeige und Versionierung relevant sind, ist die modId die kritische Variable, die das interne Referenzsystem (Namespaces) mit der Code-Generierung (Java-Pakete, Datei-Pfade) verknüpft. Eine Änderung der modId ist daher ein tiefgreifender Eingriff, der die Validität aller Referenzen im Projekt beeinflusst. Welche Rollen übernehmen Renderer, Preload-Bridge und Main-Process? Welche drei Objekttypen definiert das Domainmodell für Minecraft-Mods? Wie erkennt der LogAnalyzer des Testbots einen erfolgreichen Serverstart? Diskutieren, was diese Quellen im Kontext von „Zentrale Verträge (Contracts)“ über „IPC / Bridge Spec“ aussagen.  In den vorliegenden Quellen wird das Konzept „Zentrale Verträge (Contracts)“ in Bezug auf „IPC / Bridge Spec“ als fundamentaler architektonischer Baustein behandelt. Es dient dazu, verschiedene Systemkomponenten (wie Frontend/Renderer und Backend/Main-Process) sauber zu entkoppeln, Typsicherheit zu gewährleisten und Sicherheitsgrenzen durchzusetzen. Die Quellen diskutieren dies anhand zweier unterschiedlicher Projekte: dem „Minecraft Mod Studio for Kids“ (Electron-App) und dem „Local Hub Jarvis“ (KI-Orchestrierung). In beiden Fällen definiert der IPC-Vertrag (Inter-Process Communication), wie Daten ausgetauscht werden, bevor die eigentliche Implementierung beginnt. Hier ist eine detaillierte Diskussion der Aussagen: 1. Die Bridge als Sicherheits- und Vertrauensgrenze Die Quellen definieren die IPC-Bridge nicht nur als Transportweg, sondern als harte Sicherheitsgrenze („Trust Boundary“). • Untrusted UI vs. Privileged Main: Im Kontext der Electron-App wird der Renderer (UI) explizit als „untrusted“ eingestuft, während der Main-Process die Hoheit über das Dateisystem (FS) und Kindprozesse behält. Der Contract verbietet dem Renderer direkten Zugriff auf Node.js-APIs; stattdessen muss er über die window.KidMod-API gehen, die im Preload-Skript (bridge.ts) exponiert wird,. • Sandbox-Durchsetzung: Der Vertrag schreibt vor, dass der Main-Process niemals beliebige Pfade vom Renderer akzeptieren darf. Stattdessen werden Operationen wie saveProject und loadProject logisch abstrahiert: Der Renderer sendet Daten, aber der Main-Process bestimmt mittels einer „Workspace Sandbox“ (safeJoin), wo diese physisch landen, um „Path Traversal“-Angriffe zu verhindern,. • Capability Tiers: Im Jarvis-Projekt wird dieses Konzept durch „Capability Tiers“ erweitert. Der Vertrag legt fest, ob ein Skill nur lesen darf (read_only), eine lokale Bestätigung benötigt (write_local_confirm) oder destruktiv ist (destructive_two_step). 2. Das „Envelope“-Muster (Standardisierter Umschlag) Ein zentrales Element der Contracts ist die Standardisierung der Antwortformate, um Fehlerbehandlung und Parsing vorhersehbar zu machen. Beide Projekte nutzen ein striktes „Envelope“-Pattern. • Result Envelope: Anstatt rohe Daten oder geworfene Exceptions zurückzugeben, definieren die Specs ein IpcResult-Objekt. Dieses ist entweder { ok: true, data: T } oder { ok: false, error: IpcError },. • Kanonische Fehlercodes: Die Contracts legen eine feste Liste von Fehlercodes fest (z. B. E_VALIDATION, E_WORKSPACE_REQUIRED, E_IO), die stabil bleiben, auch wenn sich die interne Implementierung ändert,. Dies ermöglicht dem UI, spezifische Fehlermeldungen (Toasts, Dialoge) anzuzeigen, ohne den internen Fehlerstring parsen zu müssen. • Event Envelope: Im Jarvis-Projekt wird dies auf Events ausgeweitet. Jedes Event folgt einem Schema mit type, traceId, ts (Zeitstempel), source und payload,. Dies garantiert „Observability“ (Beobachtbarkeit) und Tracing über Systemgrenzen hinweg. 3. Contract-First und Single Source of Truth Die Quellen betonen, dass die Schnittstellendefinition vor der Implementierung erfolgen muss („Contract-first“), um „Drift“ (Abweichungen zwischen Sender und Empfänger) zu vermeiden. • Zentrale Definition:     ◦ Im Minecraft-Projekt wird dies durch TypeScript-Definitionen (bridge.d.ts) und Spezifikationsdokumente (ipc-bridge-spec-v1.md) erreicht, die als „Single Source of Truth“ dienen,.     ◦ Im Jarvis-Projekt wird dies durch einen event_catalog.json und ein Skill-Manifest gelöst,. • Code-Generierung: Um sicherzustellen, dass Python (Backend) und TypeScript (Frontend) im Jarvis-Projekt nicht auseinanderlaufen, wird ein Generator-Skript (generate_events.py) verwendet. Dieses erzeugt aus dem zentralen JSON-Katalog automatisch Pydantic-Modelle für Python und Interfaces für TypeScript. Implementierungen müssen sich diesem generierten Vertrag unterordnen. • Whitelisting von Kanälen: Die Bridge-Spec definiert explizit eine „Allowlist“ an erlaubten Kanälen (z. B. project:save, pipeline:start). Unbekannte Kanäle werden im Preload-Skript blockiert, um die Angriffsfläche zu minimieren,. 4. Datenfluss und Typisierung Die Verträge regeln detailliert, welche Datenformate über die Leitung gehen dürfen. • JSON-Serialisierbarkeit: Alle Payloads müssen JSON-serialisierbar sein; Funktionen oder binäre Blobs (außer als Base64-Strings) sind ausgeschlossen. • Domain-Validierung: Bevor Daten die Bridge passieren (z. B. beim Speichern eines Projekts), müssen sie gegen ein Domain-Schema (Zod-Schema im Core-Model) validiert werden. Der Main-Process verlässt sich nicht auf die Validierung des Renderers, sondern prüft erneut,. • Streaming-Semantik: Für langlaufende Prozesse (wie Build-Pipelines oder Voice-Chunks) definieren die Verträge eine Zustandsmaschine mit festen Phasen: start -> progress (oder chunk) -> done (oder end) / error,. Dies verhindert, dass das UI in einem undefinierten Wartezustand verharrt. 5. Entkopplung von Implementierung und Schnittstelle Durch die IPC-Contracts wird das „Refactoring“ erleichtert. • Austauschbarkeit: Da der Renderer nur gegen die window.KidMod-Schnittstelle programmiert ist, kann die Implementierung im Main-Process (z. B. Wechsel von Mock-Daten zu echtem Dateisystemzugriff) ausgetauscht werden, ohne den Renderer-Code ändern zu müssen,. • Mocking: Die Specs ermöglichen es, im Browser-Modus (ohne Electron) eine mockBridge zu nutzen, die denselben Vertrag erfüllt, aber Daten im LocalStorage oder Memory hält,. Zusammenfassung Zusammenfassend sagen die Quellen aus, dass eine „IPC / Bridge Spec“ im Kontext zentraler Verträge weit mehr ist als eine Liste von Funktionsnamen. Sie ist das Gesetzbuch der Anwendung, das definiert: 1. Wer mit wem sprechen darf (Whitelisting). 2. Welche Sprache gesprochen wird (Typen/Schemas). 3. Wie Ergebnisse und Fehler verpackt werden (Envelopes). 4. Wo die Grenzen des Vertrauens verlaufen (Security Boundaries).  -------------------------------------------------------------------------------- Analogie: Man kann sich diese IPC-Contracts wie das Protokoll an einem Hochsicherheits-Grenzposten vorstellen. Das „Untrusted UI“ ist ein Reisender, der ein Paket (Daten) abgeben will. Die „Bridge“ ist der Grenzbeamte. Er akzeptiert das Paket nicht einfach blind (kein direkter Zugriff). Stattdessen verlangt er ein standardisiertes Formular (Envelope), prüft, ob der Inhalt (Payload) den Vorschriften entspricht (Validierung), und weist den Reisenden an, in einer bestimmten Wartezone zu bleiben (Promise/Async), bis das Paket intern von spezialisiertem Personal (Main Process) sicher verarbeitet wurde. Der Reisende erfährt nie, wie das Paket intern transportiert wird, sondern erhält nur eine standardisierte Quittung („OK“ oder „Abgelehnt: Grund X“). Welche fünf Bausteine stabilisieren das System beim „intelligenten Zusammensetzen“? Welche drei Dokumente dienen laut Abschluss als verbindliche Systemverträge? Wie unterscheidet sich die „Option A“ von „Option B“ bei ID-Umbenennungen? Diskutieren, was diese Quellen im Kontext von „IPC / Bridge Spec“ über „Channels: project:save/load, pipeline:start“ aussagen.  Basierend auf den Quellen, insbesondere den Entwürfen zur „IPC / Bridge Spec v1“ und den Analyse-Reports, definieren die Quellen für die Kanäle project:save/load und pipeline:start einen strengen Übergang von einem unsicheren Prototyp-Status zu einem typisierten, abgesicherten Vertrag (Contract). Hier ist die detaillierte Diskussion der Aussagen im Kontext der Spezifikation: 1. Status Quo vs. Ziel-Spezifikation Die Quellen unterscheiden scharf zwischen dem aktuellen Zustand im Code (oft als „Stub“ oder „Mock“ bezeichnet) und der geforderten „IPC / Bridge Spec“. • Aktueller Zustand: Im Repository sind project:save und project:load im Main-Process (ipc.ts) größtenteils „Stubs“ (Platzhalter). project:save gibt zwar „success“ zurück, schreibt aber nichts auf die Festplatte, und project:load ist nicht implementiert. Der Renderer nutzt teilweise eine „MockBridge“, um im Browser ohne Electron zu funktionieren. • Die Spec (Ziel): Die „IPC / Bridge Spec v1“ fordert, dass der Main-Process die alleinige Autorität über das Dateisystem hat und der Renderer als „untrusted UI“ behandelt wird. 2. Kanäle: project:save und project:load Die Spezifikation definiert diese Kanäle als den zentralen Mechanismus für die Persistenz, abgesichert durch eine „Workspace Sandbox“. project:save • Vertrag (Request/Response): Der Renderer sendet { workspaceDir: string, project: ProjectFile }. Der Main-Process antwortet mit einem standardisierten IpcResult, das entweder { ok: true } oder { ok: false, error: ... } enthält. • Sicherheitsregeln:     ◦ Sandbox: Der Pfad darf nicht vom Renderer frei gewählt werden. Der Main-Process muss safeJoin(workspaceDir, "project.json") verwenden, um „Path Traversal“ (Ausbrechen aus dem Ordner) zu verhindern,.     ◦ Validierung: Bevor gespeichert wird, muss das Projekt durch validateProject (aus dem core-model) geprüft werden.     ◦ Atomares Schreiben: Um Datenverlust zu vermeiden, schreibt der Prozess zuerst in eine temporäre Datei und benennt diese dann um,. project:load • Vertrag: Der Renderer sendet { workspaceDir: string }. Die Antwort enthält bei Erfolg das geladene project: ProjectFile. • Logik: Der Main-Process liest die project.json aus dem Workspace, parst sie und validiert sie gegen das Schema. • Fehlerbehandlung: Wenn die Datei fehlt, muss der spezifische Fehlercode E_NOT_FOUND zurückgegeben werden; bei ungültigen Daten E_VALIDATION,. 3. Kanal: pipeline:start Dieser Kanal steuert die Build-Orchestrierung („Export -> Build -> Test“) und entkoppelt die UI von den langwierigen Hintergrundprozessen. • Vertrag: Der Renderer sendet { project: ProjectFile }. Der Main-Process antwortet sofort mit einer runId (z.B. UUID). Dies signalisiert, dass der Auftrag angenommen wurde. • Asynchroner Fortschritt: Der eigentliche Status wird über den Push-Event-Kanal pipeline:progress an den Renderer gesendet. Das Status-Objekt enthält den aktuellen Schritt (step: "export" | "build" | "test" | "done" | "error"), eine Nachricht und optional Details,. • Validierung: Auch hier muss pipeline:start das Projekt validieren, bevor der teure Build-Prozess angestoßen wird. • Verbindung zu Services: Der IPC-Handler ruft intern den buildService.ts auf, der wiederum den exporter und testbot koordiniert. 4. Übergreifende Prinzipien der „Bridge Spec“ Die Quellen betonen mehrere Konzepte, die für alle genannten Kanäle gelten: • Standardisierter Umschlag (Envelope): Alle IPC-Antworten folgen dem Schema IpcResult<T>. Das eliminiert das Raten, ob eine Operation erfolgreich war, und erzwingt typisierte Fehlercodes wie E_WORKSPACE_REQUIRED oder E_BUILD_FAILED,. • Single Source of Truth: Das Datenformat für project ist strikt durch die „Project JSON Spec v1“ (Schema Version 1) definiert. Die IPC-Schicht ist der Gatekeeper, der sicherstellt, dass nur valide Daten dieses Formats gespeichert oder gebaut werden. • Whitelist Enforcement: Die Datei bridge.ts im Preload soll sicherstellen, dass nur explizit definierte Kanäle (wie die oben genannten) genutzt werden dürfen (VALID_CHANNELS), was derzeit im Code noch nicht strikt durchgesetzt wird,. Zusammenfassung Im Kontext der „IPC / Bridge Spec“ sagen die Quellen aus, dass project:save/load keine simplen Dateioperationen sind, sondern abgesicherte Transaktionen, die Validierung und Sandboxing erzwingen. pipeline:start ist der Auslöser für einen komplexen Zustandsautomaten (Build Pipeline), der über eine ID und Events asynchron kommuniziert, statt das UI zu blockieren. Analogie: Man kann sich die IPC-Bridge wie den Schalter in einer Bank vorstellen. • Der Renderer (Kunde) darf nicht direkt in den Tresor (Dateisystem) greifen. • Bei project:save (Einzahlung) prüft der Bankangestellte (Main Process) erst, ob das Geld echt ist (validateProject) und legt es dann sicher in das richtige Schließfach (safeJoin), nicht irgendwo auf den Flur. • Bei pipeline:start (Kreditantrag) gibt der Kunde die Unterlagen ab, erhält eine Vorgangsnummer (runId) und wird später per Post (pipeline:progress) über den Status informiert, statt am Schalter zu warten. Welche drei Komponenten umfasst die Build-Pipeline laut „buildService.ts“? Wie unterscheidet sich die „mockBridge“ von der echten IPC-Bridge? Welche Sicherheitsregeln muss der Main-Prozess bei Dateioperationen zwingend erzwingen? Diskutieren, was diese Quellen im Kontext von „IPC / Bridge Spec“ über „Channels: project:save/load, pipeline:start“ aussagen.  Basierend auf den Quellen, insbesondere der Dokumentation zum „Minecraft Mod Studio for Kids“ und den dort definierten Spezifikationen, lässt sich die Rolle und Definition der Channels project:save/load und pipeline:start wie folgt zusammenfassen. Die Quellen unterscheiden dabei stark zwischen dem aktuellen Ist-Zustand (teilweise „Stubs“ oder Platzhalter) und dem definierten Soll-Zustand (der „IPC / Bridge Spec v1“), der implementiert werden soll, um das System zu stabilisieren. 1. Kontext: IPC / Bridge Architektur Die Architektur trennt strikt zwischen dem Renderer (React UI, unsicher) und dem Main Process (Electron, Zugriff auf Dateisystem/Build-Tools). Die Kommunikation läuft über eine „Bridge“ (window.KidMod), die IPC-Calls (Inter-Process Communication) nutzt,. Ein zentrales Prinzip der Spezifikation ist, dass der Renderer niemals direkten Zugriff auf das Dateisystem (fs) oder Kindprozesse (child_process) haben darf. Der Main Process fungiert als Autorität für Workspace-Operationen und die Build-Pipeline.  -------------------------------------------------------------------------------- 2. Channels: project:save und project:load Diese Channels dienen der Persistenz des Projekts (project.json) im Dateisystem. Aktueller Status (Ist-Zustand): • Im aktuellen Code (ipc.ts) sind diese Funktionen größtenteils „Stubs“ (Platzhalter). • project:save gibt zwar success: true zurück, schreibt aber faktisch noch keine Daten. • project:load ist als „not implemented“ markiert. • Der Renderer nutzt für Demos im Browser teilweise eine „MockBridge“, um diese fehlende Funktionalität zu simulieren. Spezifikation (Soll-Zustand / Spec v1): Die Quellen definieren einen strikten Vertrag („Contract“) für diese Channels, um Sicherheit und Datenintegrität zu gewährleisten: • project:save:     ◦ Request: Muss { "workspaceDir": "/abs/path", "project": { ...ProjectFile... } } enthalten.     ◦ Verhalten:         ▪ Der Main-Prozess muss erzwingen, dass nur im workspaceDir gespeichert wird (Schutz vor Path Traversal via safeJoin).         ▪ Vor dem Speichern muss das Projekt mittels validateProject validiert werden (Schema + Semantik).         ▪ Das Speichern soll „atomisch“ erfolgen (schreiben in temporäre Datei -> umbenennen), um Datenverlust zu verhindern,.     ◦ Response: { ok: true } oder { ok: false, error: IpcError }. • project:load:     ◦ Request: { "workspaceDir": "/abs/path" }.     ◦ Verhalten:         ▪ Liest project.json aus dem angegebenen Workspace (unter Verwendung von safeJoin).         ▪ Validiert die geladene Datei; bei Fehlern wird E_VALIDATION zurückgegeben.     ◦ Response: { ok: true, project: ProjectFile } oder Fehler.  -------------------------------------------------------------------------------- 3. Channel: pipeline:start Dieser Channel ist der Auslöser für den Kernprozess der Anwendung: Exportieren, Bauen und Testen des Minecraft-Mods. Aktueller Status (Ist-Zustand): • Dieser Teil ist im buildService.ts bereits realer implementiert als die Speicher-Funktionen. Er orchestriert die Schritte Export, Gradle Build und Testbot. • Er nutzt Push-Events (pipeline:progress), um den Fortschritt an das UI zu melden. Spezifikation (Soll-Zustand / Spec v1): Die Spec formalisiert diesen Ablauf und die Rückgabewerte, um die UI-Steuerung (z.B. den „Stepper“ im Dialog) robust zu machen. • pipeline:start:     ◦ Request: { "project": { ...ProjectFile... } }.     ◦ Verhalten:         ▪ Validiert das Projekt vor dem Start.         ▪ Startet den asynchronen Prozess: Export -> Build -> Test.         ▪ Prüft auf Konkurrenz: Wenn bereits eine Pipeline läuft, wird E_PIPELINE_RUNNING zurückgegeben.     ◦ Response: Gibt sofort eine runId zurück: { ok: true, runId: "..." }. Dies bestätigt nur den Start der Pipeline, nicht das Ergebnis. • Verbindung zu Events (pipeline:progress):     ◦ Da pipeline:start asynchron ist, sendet der Main-Prozess Updates über den Channel pipeline:progress.     ◦ Payload: { runId: string, status: PipelineStatus }.     ◦ Status-Schritte: export, build, test, done, error.     ◦ Dies ermöglicht dem UI (BuildDialog.tsx), dem Nutzer genau anzuzeigen, was gerade passiert (z.B. "Building your mod...") oder warum etwas fehlgeschlagen ist (mit Details aus den Logs). Zusammenfassung der Sicherheitsregeln Für alle genannten Channels gilt laut der „IPC / Bridge Spec“: 1. Validierung: Der Main-Process darf dem Renderer nicht blind vertrauen. Alle Inputs müssen validiert werden (z.B. via Zod-Schema). 2. Sandbox: Dateipfade dürfen niemals direkt vom Renderer vorgegeben werden (außer der Auswahl des workspaceDir über einen System-Dialog). Operationen müssen innerhalb des Workspaces „gefangen“ bleiben (assertInWorkspace),. 3. Typisierung: Die Kommunikation folgt einem standardisierten Envelope (IpcResult<T>), der entweder { ok: true, data: ... } oder { ok: false, error: ... } enthält, um Fehlerbehandlung im UI konsistent zu machen. Welche drei Komponenten umfasst die Build-Pipeline laut „buildService.ts“? Wie unterscheidet die „ID Rename Policy“ zwischen Option A und B? Welche Sicherheitsregeln muss der Main-Prozess laut IPC-Spec erzwingen? Diskutieren, was diese Quellen im Kontext von „Zentrale Verträge (Contracts)“ über „Error Catalog“ aussagen.  Basierend auf den vorliegenden Quellen beschreibt der „Error Catalog“ (Fehlerkatalog) einen zentralen architektonischen Vertrag (Contract), der die Fehlerbehandlung standardisiert, entkoppelt und benutzerfreundlich gestaltet. Er wird sowohl im Kontext des „Minecraft Mod Studio for Kids“ als auch im „Jarvis“-System als essenzieller Baustein für stabile Softwarearchitektur definiert. Hier ist eine detaillierte Analyse dessen, was die Quellen über den Error Catalog aussagen: 1. Definition und Zielsetzung Der Error Catalog wird als ein verbindliches Dokument definiert (konkret docs/contracts/error-catalog-v1.md), das den Status eines „Draft v1“ hat und vom „Core Team“ verantwortet wird. Seine Hauptziele sind: • Stabilität: Definition fester Fehlercodes, auf die sich Frontend (Renderer) und Backend (Main/Exporter) verlassen können. • Benutzerfreundlichkeit: Trennung von kindgerechten, verständlichen Nachrichten (User message) und technischen Details für Entwickler (Developer details). • Vermeidung von „String-Typing“: Fehler sollen nicht anhand von rohen Fehlermeldungen (Stack Traces) im UI erraten werden, sondern über definierte Codes klassifiziert sein. 2. Struktur des Fehler-Envelopes (Umschlag) Die Quellen definieren ein striktes JSON-Format („Envelope“) für die Kommunikation von Fehlern, insbesondere über IPC (Inter-Process Communication) und WebSocket-Schnittstellen. Das Format lautet: {   "ok": false,   "error": {     "code": "E_CODE_NAME",     "message": "Benutzerfreundlicher Text",     "details": "Optional: Logs, Stacktrace, Pfade"   } } Diese Struktur wird sowohl im Minecraft-Projekt als auch im Jarvis-Manifest verwendet. 3. Kanonische Fehlercodes Der Error Catalog legt eine feste Liste von Fehlercodes fest, die bestimmte semantische Zustände abbilden. Die wichtigsten in den Quellen genannten Codes sind: • E_VALIDATION: Tritt auf, wenn das Domänenmodell (z. B. validateProject) Schema- oder Semantikfehler meldet (z. B. ungültige Referenzen in Rezepten). Das UI soll hierbei Hinweise zur Korrektur geben. • E_WORKSPACE_REQUIRED: Wird geworfen, wenn der Nutzer versucht zu speichern oder zu exportieren, ohne einen Arbeitsordner gewählt zu haben. • E_PATH_TRAVERSAL: Ein Sicherheitsfehler, wenn ein Pfad versucht, aus der Sandbox (dem Workspace) auszubrechen. • E_BUILD_FAILED: Spezifisch für die Pipeline; tritt auf, wenn der Gradle-Build fehlschlägt (z. B. Exit-Code ungleich 0). • E_TEST_FAILED: Der Build war erfolgreich, aber der anschließende Test (z. B. runServer) schlug fehl (Timeout oder Absturz). • E_IO: Allgemeine Schreib-/Lesefehler (z. B. fehlende Berechtigungen oder volle Festplatte). • E_NOT_FOUND: Eine erwartete Datei (z. B. project.json beim Laden) fehlt. Für das Jarvis-System werden zusätzlich Codes wie E_RESOURCE_LIMIT oder E_DEPENDENCY_UNAVAILABLE ergänzt, was die Erweiterbarkeit des Katalogs zeigt. 4. Mapping und UI-Regeln Der Katalog definiert nicht nur die Codes, sondern auch Regeln für deren Darstellung und Ursprung: • Mapping-Regeln: Es wird explizit festgelegt, welche technischen Ereignisse zu welchen Codes führen. Ein gradle exit != 0 muss z. B. zwingend zu E_BUILD_FAILED gemappt werden. Ein JSON-Parse-Fehler beim Laden wird zu E_VALIDATION. • UI-Verhalten:     ◦ Bei E_VALIDATION soll das UI konkrete Hinweise geben ("Fix something in your mod first").     ◦ Bei E_WORKSPACE_REQUIRED soll idealerweise direkt der Ordner-Auswahl-Dialog geöffnet werden.     ◦ Rohe Stack Traces dürfen niemals standardmäßig angezeigt werden, sondern nur hinter einem „Show details“-Expander. 5. Strategische Bedeutung im Refactoring In der Refactoring-Strategie wird der Error Catalog als Teil des „Contracts-first“-Prinzips hervorgehoben. • Entkopplung: Durch das „Error-Envelope“ wird das Debugging vereinfacht, da Fehlerursachen (Domain vs. Pipeline vs. IO) klar unterscheidbar sind. • Definition of Done: Ein Feature gilt erst als fertig („Done“), wenn Fehlerbilder über das definierte Error-Envelope sichtbar sind. • Single Source of Truth: Der Katalog verhindert Diskussionen während der Implementierung, da das Verhalten im Fehlerfall vorab definiert ist. Zusammenfassung & Analogie Die Quellen beschreiben den Error Catalog als das „diplomatische Protokoll“ zwischen den unsicheren, chaotischen Teilen der Anwendung (Dateisystem, externe Builds, Benutzereingaben) und der geordneten Benutzeroberfläche. Anstatt dass das UI versucht, rohe technische Schreie („Exception in thread main...“) zu interpretieren, übersetzt das Backend (Main Process/Kernel) diese Probleme mithilfe des Katalogs in eine vereinbarte „Sprache“ (E_BUILD_FAILED), die das UI versteht und dem Nutzer (Kind) höflich erklären kann („Dein Mod konnte nicht gebaut werden. Lass uns das reparieren!“). Welche drei Export-Dateien werden für das Fabric-Mod-Projekt generiert? Welche drei Phasen sieht der "Wiring Plan" zur Systemstabilisierung vor? Welche Aufgaben übernimmt die "Preload Bridge" in der Electron-Architektur? Diskutieren, was diese Quellen im Kontext von „Error Catalog“ über „Codes: E_VALIDATION, E_BUILD_FAILED, etc.“ aussagen.  Die Analyse der Quellen zeigt, dass der „Error Catalog“ ein zentrales architektonisches Element ist, um Stabilität, Sicherheit und Benutzerfreundlichkeit in den beschriebenen Systemen (Minecraft Mod Studio und Jarvis Hub) zu gewährleisten. Die Quellen definieren ein „Contract-first“-Prinzip, bei dem Fehler nicht zufällig geworfen, sondern als strukturierte Datenobjekte (Envelopes) über Prozessgrenzen hinweg (IPC oder API) transportiert werden,,. Hier ist eine detaillierte Diskussion der Aussagen zu den Fehlercodes: 1. Das Konzept des „Error Envelope“ (Die Hülle) Anstatt einfache Exceptions zu nutzen, definieren die Quellen ein striktes Antwortformat für IPC- (Inter-Process Communication) und API-Aufrufe. Jede Operation gibt entweder ein Erfolgs- oder ein Fehlerobjekt zurück: • Struktur: { ok: false, error: { code, message, details? } },. • Ziel: Dies entkoppelt die Benutzeroberfläche (Renderer) von der Logik (Main/Backend). Die UI muss den Fehler nicht verstehen, sondern nur wissen, wie sie den code und die message darstellt. 2. Diskussion der spezifischen Fehlercodes Die Quellen kategorisieren Fehlercodes nach ihrer Domäne (Validierung, Build-Prozess, Sicherheit, Infrastruktur). A. E_VALIDATION: Die Wächter der Fachlichkeit Dieser Code ist der wichtigste Mechanismus, um die Integrität des Datenmodells („Core Domain Truth“) zu schützen. • Bedeutung: Er signalisiert, dass die Eingabedaten (z. B. das project.json oder eine Chat-Eingabe) nicht dem definierten Schema oder den semantischen Regeln entsprechen,. • Auslöser:     ◦ Verletzung des Zod-Schemas (z. B. falsches Format einer Mod-ID).     ◦ Semantische Fehler, wie ein Rezept, das auf ein nicht existierendes Item verweist.     ◦ Inkonsistente Referenzen (Key entspricht nicht der ID). • UI-Darstellung (User Experience): Die Quellen legen großen Wert auf kindgerechte Ansprache. Statt technischer Details soll die Meldung lauten: „In deinem Mod stimmt etwas noch nicht. Bitte repariere es“ oder „Fix something in your mod first“,. • Developer Details: Für Entwickler oder Eltern enthält das details-Feld den genauen JSON-Pfad (z. B. /recipes/r1/key/R) und den technischen Grund. B. E_BUILD_FAILED & E_TEST_FAILED: Die Pipeline-Zustände Diese Codes sind spezifisch für die Build-Orchestrierung im Minecraft Mod Studio. Sie transformieren unstrukturierte Konsolenausgaben (Logs) in deterministische Zustände. • E_BUILD_FAILED:     ◦ Bedeutung: Der Export oder der Gradle-Build-Prozess war nicht erfolgreich.     ◦ Auslöser: Ein Exit-Code ungleich 0 bei Gradle, fehlende Java-Installation oder fehlende Output-Artefakte (JAR-Datei),.     ◦ UI: „Dein Mod konnte nicht gebaut werden“. • E_TEST_FAILED:     ◦ Bedeutung: Der Build war erfolgreich, aber der anschließende Testlauf (Starten des Minecraft-Servers) schlug fehl.     ◦ Auslöser: Ein Timeout (Server startet nicht rechtzeitig) oder ein „Crash-Pattern“ in den Logs (z. B. „Mixin apply failed“),.     ◦ Diagnose: Das System analysiert die Logs (LogAnalyzer), um zwischen einem Build-Fehler und einem Laufzeit-Fehler zu unterscheiden, was für das Feedback an den Nutzer essenziell ist. C. E_PATH_TRAVERSAL & E_WORKSPACE_REQUIRED: Sicherheit und Kontext Diese Codes erzwingen die „Sandbox“-Architektur, bei der die UI als „untrusted“ (nicht vertrauenswürdig) gilt. • E_PATH_TRAVERSAL: Wird geworfen, wenn ein Pfad versucht, aus dem erlaubten Workspace auszubrechen (z. B. durch ../). Dies wird durch Hilfsfunktionen wie safeJoin im Main-Prozess erzwungen,. • E_WORKSPACE_REQUIRED: Verhindert Operationen, bevor ein Arbeitsverzeichnis ausgewählt wurde. Die UI reagiert darauf oft proaktiv, z. B. durch Öffnen des Ordner-Dialogs. D. Weitere Codes (E_IO, E_BAD_REQUEST, E_UNKNOWN) • E_IO: Ein generischer Wrapper für Dateisystemfehler (Zugriffsrechte, Festplatte voll). Die kindgerechte Übersetzung lautet: „Ich kann gerade keine Dateien lesen oder schreiben“. • E_BAD_REQUEST: Signalisiert Programmierfehler im Frontend, z. B. fehlende Pflichtfelder im IPC-Aufruf. 3. Vergleich: Mod Studio vs. Jarvis System Interessanterweise nutzen beide in den Quellen beschriebenen Systeme dasselbe Muster, erweitern den Katalog aber je nach Kontext: 1. Minecraft Mod Studio: Fokussiert auf E_BUILD_FAILED, E_TEST_FAILED und E_VALIDATION für die Projektintegrität. 2. Jarvis Hub: Nutzt dieselbe Basis (E_VALIDATION, E_IO), fügt aber spezifische Codes für eine KI-Laufzeitumgebung hinzu:     ◦ E_PERMISSION_REQUIRED: Für das Sicherheitssystem (Capability Tiers).     ◦ E_RESOURCE_LIMIT: Wenn CPU/VRAM ausgelastet sind.     ◦ E_DEPENDENCY_UNAVAILABLE: Wenn ein Skill (z. B. STT/TTS) nicht geladen ist. 4. Synthese: Warum ein Error Catalog? Die Quellen argumentieren, dass dieser Katalog notwendig ist, um das System „intelligent wieder zusammenzusetzen“. Durch die Standardisierung der Fehlercodes: 1. Entkopplung: Kann der Renderer Fehler anzeigen, ohne die dahinterliegende Technologie (Gradle, Python, Node) zu kennen. 2. Sicherheit: Werden interne Stack-Traces vor dem Nutzer verborgen und nur „sanitized“ Messages angezeigt. 3. Typ-Sicherheit: Können TypeScript und Python (via Pydantic) denselben Vertrag nutzen, was „Drift“ zwischen Backend und Frontend verhindert,. Zusammenfassend ist der „Error Catalog“ in diesen Quellen nicht nur eine Liste von Konstanten, sondern das zentrale Protokoll für die Resilienz der Anwendung, das definiert, wie technische Ausnahmen in verständliches Nutzer-Feedback übersetzt werden. Welche Rollen übernehmen der Main Process und der Renderer bei „Minecraft Mod Studio“? Wie unterscheidet sich die Handhabung von „preset“-Texturen gegenüber „dataUri“-Texturen beim Export? Welche drei Phasen sieht der „Wiring Plan“ für die System-Stabilisierung vor? Diskutieren, was diese Quellen im Kontext von „Error Catalog“ über „User-Messages: Kindgerechte Texte“ aussagen.  Basierend auf den Quellen, insbesondere dem Entwurf für den „Error Catalog v1“, spielen „User-Messages: Kindgerechte Texte“ eine zentrale Rolle in der UX-Philosophie des Minecraft Mod Studios. Die Quellen definieren hierbei nicht nur, dass Fehler gemeldet werden, sondern schreiben strikt vor, wie diese kommuniziert werden müssen, um die Zielgruppe (Kinder) nicht zu entmutigen. Hier ist eine Diskussion darüber, was die Quellen über dieses Konzept aussagen: 1. Prinzipien der kindgerechten Kommunikation Der „Error Catalog“ legt fest, dass technische Fehler für den Nutzer abstrahiert werden müssen. Die oberste Regel lautet: „Always show a short, friendly message“ (Zeige immer eine kurze, freundliche Nachricht) und „Never show raw stack traces by default“ (Zeige standardmäßig niemals rohe Stack-Traces). Die Kommunikation folgt dabei einem pädagogischen Ansatz: • Kein technischer Jargon: Begriffe wie „Schema Validation“, „Gradle Exit Code“ oder „IO Exception“ sind verboten und werden durch verständliche Konzepte ersetzt. • Lösungsorientierung: Anstatt nur das Problem zu benennen („Fatal Error“), motivieren die Texte zur Handlung (z. B. „Let's fix it!“ oder „Pick a folder first“),. • Entschärfung: Wörter wie „Oops!“ oder „Uh oh“ werden genutzt, um Fehler weniger bedrohlich wirken zu lassen,. 2. Mapping von Fehlercodes zu Kindgerechten Texten Die Quellen definieren eine klare Trennung zwischen dem technischen code (für die Programlogik) und der message (für das Kind). Hier sind spezifische Beispiele aus dem Katalog: • E_VALIDATION (Validierungsfehler):     ◦ Technisch: Schema-Verletzung oder semantischer Fehler.     ◦ Kindgerecht: „Oops! One part of your mod does not make sense yet.“ (Hoppla! Ein Teil deines Mods ergibt noch keinen Sinn.).     ◦ Ziel: Das Kind soll verstehen, dass der Mod „Reparatur“ benötigt, ohne sich für einen Syntaxfehler verurteilt zu fühlen. • E_BUILD_FAILED (Build-Fehler):     ◦ Technisch: Gradle-Prozess fehlgeschlagen / Exit Code != 0.     ◦ Kindgerecht: „Your mod did not build. Let's fix it!“ (Dein Mod konnte nicht gebaut werden. Lass uns das reparieren!).     ◦ Ziel: Den Fehler als gemeinsame Herausforderung („Let's“) statt als Sackgasse darstellen. • E_WORKSPACE_REQUIRED (Fehlender Ordner):     ◦ Technisch: Pfad ist null.     ◦ Kindgerecht: „Pick a folder first so I know where to save your mod!“ (Wähle erst einen Ordner, damit ich weiß, wo ich speichern soll!). • E_TEST_FAILED (Test-Fehler):     ◦ Technisch: Server-Timeout oder Crash-Log.     ◦ Kindgerecht: „Your mod built, but the test world did not start.“ (Dein Mod wurde gebaut, aber die Testwelt ist nicht gestartet.). 3. Architektur der Fehlerdarstellung (UI) Die Quellen beschreiben eine UI-Architektur, die Sicherheit für das Kind mit Debugging-Möglichkeiten für Erwachsene (Eltern/Mentoren) verbindet: • User-Message (Standard): Das Kind sieht nur die freundliche Nachricht. • Developer Details (Optional): Es gibt ein Feld details, das Logs, Stack-Traces oder spezifische Pfade enthält. Dieses wird jedoch nur in einem optionalen „Show details“-Expander angezeigt,. • Visuelles Feedback: Fehler werden über Toasts (für flüchtige Fehler) oder im Build-Dialog (für Pipeline-Fehler) angezeigt, oft farblich kodiert, aber textlich entschärft. 4. Lokalisierung (Deutsche Beispiele) Die Quellen liefern explizit deutsche Übersetzungen für diese kindgerechten Texte, was die Wichtigkeit der Muttersprache für die Zielgruppe unterstreicht. Beispiele hierfür sind: • E_WORKSPACE_REQUIRED: „Bitte wähle zuerst einen Ordner, damit ich weiss, wo ich speichern soll!“. • E_VALIDATION: „In deinem Mod stimmt etwas noch nicht. Bitte repariere es und versuch es nochmal.“. • E_IO: „Ich kann gerade keine Dateien lesen oder schreiben.“ (statt „Permission Denied“). 5. Integration mit „Creeper-Flavor“ Neben Fehlern erwähnen die Quellen auch explain.ts, ein Modul, das erfolgreiche Aktionen erklärt (z. B. „Ich habe deinen Block erstellt“). Auch hier wird ein „Creeper-Flavor“ erwähnt, was darauf hindeutet, dass die Texte thematisch passend zum Minecraft-Universum formuliert sein sollen, um die Immersion aufrechtzuerhalten. Zusammenfassend betrachten die Quellen die Fehlerbehandlung nicht als rein technisches Logging, sondern als Kernbestandteil der User Experience. Der „Error Catalog“ fungiert als Vertrag, der sicherstellt, dass das System niemals „rohe Technik“ ausspuckt, sondern stets als freundlicher Assistent agiert, der dem Kind hilft, Hindernisse zu überwinden. Welche Phasen sieht der Wiring-Plan für die System-Stabilisierung vor? Welche drei Komponenten umfasst die Build-Pipeline laut den Architektur-Pfaden? Wie unterscheidet sich die Fehlerbehandlung zwischen Renderer und Main-Prozess? Diskutieren, was diese Quellen im Kontext von „Minecraft Mod Studio for Kids (Repo-Analyse)“ über „Re-Assembly Plan“ aussagen.  Basierend auf den vorliegenden Quellen, insbesondere dem „Assembly Plan Checklist (v1)“ und den detaillierten „Task Breakdowns“, beschreibt der „Re-Assembly Plan“ eine strategische Vorgehensweise, um das Minecraft Mod Studio for Kids aus seinem aktuellen Status (ein Prototyp mit Platzhaltern und „Scaffolding“) in ein voll funktionsfähiges, stabiles System zu verwandeln. Die Quellen identifizieren, dass das Repo zwar strukturell vollständig ist (Monorepo mit Electron, React, Core-Model, Exporter), aber an kritischen Stellen Code-Lücken („ellipsenartige Platzhalter“ wie ...) aufweist. Der Plan zielt darauf ab, diese Lücken schichtweise zu schließen, basierend auf strikten Verträgen (Contracts). Hier ist die detaillierte Diskussion des Re-Assembly Plans: 1. Strategischer Ansatz: „Core Domain First“ Der Plan diktiert eine strikte Reihenfolge der Stabilisierung, um Abhängigkeiten sauber zu halten. Das Prinzip lautet: Erst die Wahrheit definieren, dann die I/O-Adapter bauen. • Phase 0: Repo Hygiene: Bevor Code geschrieben wird, muss die Entwicklungsumgebung (Node/pnpm Versionen) und die CI-Pipeline (pnpm -r build/test) stabilisiert werden, um eine verlässliche Basis zu schaffen. • Phase 1: Core Domain Truth (Priorität 0): Das ist der wichtigste Schritt. Das Paket @kidmodstudio/core-model muss zu 100% frei von Platzhaltern gemacht werden.     ◦ Das Zod-Schema (schema.ts) muss exakt der „Project JSON Spec v1“ entsprechen.     ◦ Die Validierung (validate.ts) muss semantische Regeln (z. B. Referenzen in Rezepten) erzwingen.     ◦ Der Reducer (reducer.ts) muss deterministisch arbeiten und Undo/Redo unterstützen.     ◦ Ziel: Alle anderen Systemteile (UI, Exporter) verlassen sich auf dieses Modell als „Single Source of Truth“. 2. Entscheidung zur Datenintegrität (ID Policy) Ein kritischer Punkt im Plan ist der Umgang mit IDs (z. B. Block-IDs). Die Quellen diskutieren zwei Optionen, empfehlen aber dringend Option A: Immutable IDs,. • Problem: Wenn IDs umbenannt werden, brechen Referenzen (z. B. in Crafting-Rezepten). • Lösung: Das UI soll IDs nach der Erstellung als unveränderlich behandeln. Umbenennungen werden technisch als „Kopie mit neuer ID + Löschen der alten ID“ umgesetzt. Dies vereinfacht den Reducer im Re-Assembly erheblich. 3. Konnektivität und Sicherheit (Phase 2 & 3) Sobald der Kern steht, werden die Schnittstellen „verdrahtet“. • IPC Bridge (Phase 2): Die Verbindung zwischen Renderer (UI) und Main Process (Electron) wird über strikte Kanäle (project:save, project:load) geregelt. Der Plan verlangt hier zwingend die Nutzung einer Workspace Sandbox (assertInWorkspace), um Sicherheitslücken wie Path Traversal zu verhindern,. • Exporter Determinismus (Phase 3): Der Exporter darf nicht „irgendwie“ exportieren, sondern muss ein deterministisches Manifest erzeugen (Project JSON Spec → Fabric Mod). Ein wichtiger Aspekt hierbei ist die Behandlung von Texturen: Der Plan empfiehlt, Texturen bevorzugt als dataUri im Projekt zu speichern, damit der Exporter sie einfach in PNG-Dateien umwandeln kann, ohne externe Abhängigkeiten aufzulösen,. 4. Die „Build Pipeline“ Orchestrierung (Phase 4) Der Plan beschreibt, wie die einzelnen Tools (Exporter, Gradle, Testbot) zu einer nutzerfreundlichen Pipeline verknüpft werden. • Ablauf: Der buildService im Main-Process koordiniert den Fluss: Export -> Build -> Test. • Status-Events: Es müssen klare Fortschrittsmeldungen (Progress Events) an das UI gesendet werden, damit der Nutzer im „BuildDialog“ nicht hängen gelassen wird (z. B. „Building your mod...“). • Fehlerbehandlung: Der Plan führt einen „Error Catalog“ ein, damit technische Fehler (z. B. Gradle Exit Code != 0) in kindgerechte Fehlermeldungen übersetzt werden (z. B. „Dein Mod konnte nicht gebaut werden. Lass uns das reparieren!“),. 5. Definition of Done (DoD) Für jede Phase definiert der Re-Assembly Plan klare Erfolgskriterien („Definition of Done“), um sicherzustellen, dass das System wirklich zusammengesetzt ist und nicht nur „kompiliert“: • Core: Tests sind grün (pnpm test). • Persistence: Ein Projekt kann gespeichert, die App neu gestartet und das identische Projekt wieder geladen werden. • Export: Der Befehl ./gradlew build im exportierten Ordner läuft erfolgreich durch. • Pipeline: Der „One-Click“-Prozess im UI läuft durch und zeigt Fehler verständlich an. Zusammenfassung Die Quellen präsentieren den Re-Assembly Plan als Anleitung zur „Ent-Skelettierung“. Das Repo wird als ein Gerüst (Scaffold) verstanden, bei dem die Verbindungen („Naehte“) und Schnittstellen klar sind, aber die Implementierung an vielen Stellen (insb. im Core-Model und Exporter) erst durch die Anwendung der definierten Verträge (Contracts) finalisiert („ausbetoniert“) werden muss,. Welche drei Komponenten umfasst die Build-Pipeline laut dem Architektur-Blueprint? Wie stellt das System den Schutz vor Path-Traversal-Angriffen sicher? Welche Regeln gelten für die Benennung einer ModId im Project-Schema? Diskutieren, was diese Quellen im Kontext von „Re-Assembly Plan“ über „Phase 1: core-model stabilisieren (keine Platzhalter)“ aussagen.  Im „Re-Assembly Plan“ wird Phase 1: core-model stabilisieren als der absolut kritische erste Schritt definiert, um das „Minecraft Mod Studio for Kids“ von einem Prototyp mit Platzhaltern in ein funktionierendes System zu verwandeln. Die Quellen beschreiben diese Phase als die Herstellung einer „Single Source of Truth“ (einzige Wahrheitsquelle), auf die sich alle anderen Komponenten (UI, Exporter, IPC) verlassen müssen. Hier ist eine detaillierte Diskussion dessen, was die Quellen über diese Phase aussagen: 1. Das Problem: Platzhalter und „Scaffold“-Status Die Quellen identifizieren, dass das aktuelle Repository im core-model (dem Domänenkern) an mehreren Stellen unvollständigen Code enthält, der oft durch Ellipsen (...) oder abgeschnittene Zeilen markiert ist,. • Auswirkung: Solange diese Platzhalter existieren, sind die Typen nicht sicher (oft any), und die Logik für Reducer oder Validierung ist lückenhaft. Dies verhindert, dass abhängige Pakete wie der renderer oder der exporter zuverlässig arbeiten können. • Ziel: Das Ziel von Phase 1 ist es, das core-model zu einer „100% sauberen Wahrheit“ zu machen, die keine technischen Schulden oder „ToDos“ mehr im Code enthält. 2. Konkrete Aufgabenpakete (Tasks) Der Plan zerlegt Phase 1 in spezifische Datei-Änderungen, um die Stabilität zu erreichen: A. Schema Finalisierung (schema.ts) Das Zod-Schema muss exakt die „Project JSON Spec v1“ abbilden. • Strenge Typisierung: Es dürfen keine Platzhalter mehr existieren. Es müssen Regex-Regeln für IDs (^[a-z0-9_]+$) und Zod-Unions für Texturen (preset vs. dataUri) implementiert werden,. • Datenstruktur: Die Container für blocks, items und recipes müssen als Records definiert werden, und das Feld schemaVersion: 1 wird als Literal festgelegt. B. Semantische Validierung (validate.ts) Es reicht nicht, nur die JSON-Struktur zu prüfen. Phase 1 verlangt die Implementierung von validateProject, um logische Integrität zu sichern. • Invarianten: Es muss geprüft werden, ob der Key in einem Record exakt der id des Objekts entspricht. • Referenz-Checks: Referenzen in Rezepten müssen validiert werden (existiert das Item im Projekt oder ist es ein minecraft:-Item?),. • Textur-Regeln: Presets müssen gegen eine Whitelist (z. B. "rock", "wood") geprüft werden. C. Typ-sichere Actions (actions.ts) Die Quellen fordern das Entfernen aller any-Typen aus den Redux-Actions. • Explizite Typen: Aktionen wie CREATE_BLOCK, UPDATE_ITEM oder LOAD_PROJECT müssen vollständig typisiert sein,. • Entscheidung ID-Policy: Hier liegt ein kritischer Entscheidungspunkt („Decision Gate“). Es wird empfohlen, IDs als immutable (unveränderlich) zu behandeln. Das bedeutet, statt einer komplizierten RENAME-Action (die alle Referenzen aktualisieren müsste), soll das System Umbenennungen durch „Kopieren + Löschen“ lösen,. D. Deterministischer Reducer (reducer.ts) Der Reducer muss repariert werden, um reine Funktionen und deterministische Updates zu garantieren. • History-Management: Die Logik für Undo/Redo (past, future Stacks) muss im rootReducer implementiert werden und darf nur den Domänenzustand (project), nicht den UI-Zustand beeinflussen,. • Isolation: Der Reducer darf keine Seiteneffekte haben und muss fehlerhafte Inputs (z. B. Löschen einer nicht existierenden ID) robust ignorieren. 3. Strategische Bedeutung Die Quellen betonen das Prinzip „Core zuerst“. • Entkopplung: Indem Phase 1 zuerst abgeschlossen wird, entstehen klare Grenzen („Boundaries“). Der IPC-Layer und der Exporter werden später lediglich Daten konsumieren, die durch das core-model bereits validiert wurden,. • Vermeidung von Blockern: Ohne Phase 1 müssten UI-Entwickler raten, wie die Datenstruktur aussieht, was zu „Integration Hell“ führt. Ein stabiles Core-Model dient als Vertrag für alle anderen Entwickler. 4. Definition of Done (DoD) Phase 1 gilt erst als abgeschlossen, wenn harte Kriterien erfüllt sind: • Tests: Der Befehl pnpm -C packages/core-model test muss erfolgreich durchlaufen („grün“ sein),. • Keine Platzhalter: Es dürfen keine ... oder unfertigen Typ-Definitionen mehr im Code vorhanden sein. • Validierungs-Beispiel: Das Beispiel-Projekt aus der Spezifikation muss erfolgreich durch die Validierung laufen. Zusammenfassend sagen die Quellen aus, dass Phase 1 kein bloßes „Aufräumen“ ist, sondern die architektonische Voraussetzung, um das Mod Studio überhaupt erst zusammensetzbar und testbar zu machen. Ohne diese Stabilisierung bleiben alle anderen Komponenten (Exporter, UI) auf wackeligem Fundament. Welche fünf Bausteine bilden die Grundlage des Re-Assembly Plans? Was ist das Ziel der „Trust & Safety Sandbox“? Welche drei Dokumente dienen als verbindliche Verträge für das Repo? Diskutieren, was diese Quellen im Kontext von „Re-Assembly Plan“ über „Phase 2: Persistence & Sandbox (IPC)“ aussagen.  Im Kontext des „Re-Assembly Plan“ für das „Minecraft Mod Studio for Kids“ markiert Phase 2: Persistence & Sandbox (IPC) den Übergang von einem Prototypen mit „Dummy-Funktionen“ zu einer sicher und real funktionierenden Desktop-Anwendung. Die Quellen beschreiben diese Phase als kritisch für die Sicherheit und Datenintegrität. Hier wird die Grenze (Trust Boundary) zwischen der unsicheren Benutzeroberfläche (Renderer) und dem privilegierten Hauptprozess (Main) definiert und gehärtet. Hier ist eine detaillierte Diskussion der Aussagen der Quellen zu dieser Phase: 1. Das Sicherheitskonzept: „Trust Boundary“ & Sandbox Die Quellen betonen, dass der Renderer (das UI) als „untrusted“ (nicht vertrauenswürdig) behandelt werden muss. Er darf niemals direkten Zugriff auf das Dateisystem oder Kindprozesse haben. • Die Sandbox-Regel: Der Main-Prozess ist die einzige Autorität für Dateioperationen. Er darf niemals absolute Pfade vom Renderer akzeptieren, sondern muss alle Dateizugriffe auf das ausgewählte workspaceDir beschränken. • Technische Umsetzung (workspace.ts): Die Funktion safeJoin(root, ...parts) und assertInWorkspace dienen als Wächter. Sie verhindern „Path Traversal“-Angriffe (z. B. ../../windows/system32), indem sie sicherstellen, dass der aufgelöste Pfad immer innerhalb des Workspace-Ordners liegt. • Fehlerfall: Versucht das UI, aus dem Ordner auszubrechen, muss der IPC-Call mit dem Fehlercode E_PATH_TRAVERSAL abgelehnt werden. 2. Implementierung der Persistenz (Save/Load) Aktuell (im Quellcode-Zustand des Repos) sind die Funktionen zum Speichern und Laden teilweise nur „Stubs“ (Platzhalter), die Erfolg simulieren, aber nichts schreiben. Phase 2 fordert die echte Implementierung: • Atomares Speichern (project:save): Um Datenkorruption zu verhindern, darf nicht direkt in die project.json geschrieben werden. Stattdessen schreibt der Main-Prozess in eine temporäre Datei (z. B. project.json.tmp) und benennt diese anschließend um. Dies garantiert, dass die Datei auch bei einem Absturz während des Speicherns intakt bleibt. • Validiertes Laden (project:load): Bevor eine geladene Datei an das UI gesendet wird, muss sie im Main-Prozess durch die validateProject-Logik des Core-Models laufen. Ungültige oder beschädigte Dateien führen zum Fehler E_VALIDATION oder E_NOT_FOUND, anstatt das UI crashen zu lassen. • Workspace-Auswahl: Der Dialog dialog:selectWorkspace liefert den absoluten Pfad zum Arbeitsordner zurück, der dann für alle Folgesteps als Basis dient. 3. Der IPC-Vertrag (Bridge Spec) Um die Kommunikation zu stabilisieren, definieren die Quellen einen strengen Vertrag („Contract“) für die „Bridge“ (window.KidMod). • Envelope-Pattern (Umschlag): Antworten folgen einem strikten Typ-Schema:     ◦ Erfolg: { ok: true, data: ... }     ◦ Fehler: { ok: false, error: { code, message, details } }. Dies zwingt den Renderer dazu, Fehler explizit zu behandeln, anstatt sie zu ignorieren. • Whitelist-Zwang: In der Datei bridge.ts (Preload) muss eine Liste erlaubter Kanäle (Whitelist) erzwungen werden. Versucht der Renderer, einen unbekannten Kanal aufzurufen, wird dies blockiert. • Kanäle: Die wichtigsten Kanäle für diese Phase sind project:save, project:load und dialog:selectWorkspace. 4. Integration im UI (Renderer) Auf der UI-Seite muss die Datei persistence.ts so umgebaut werden, dass sie nicht mehr nur Mock-Daten liefert (außer im Browser-Demo-Modus), sondern die echten IPC-Calls nutzt. • Fehleranzeige: Fehler aus dem Main-Prozess (wie E_IO oder E_VALIDATION) werden im UI abgefangen und in benutzerfreundliche „Toasts“ (Benachrichtigungen) umgewandelt. • UX-Absicherung: Der ProjectContext muss sicherstellen, dass ein Speichervorgang ohne vorher ausgewähltes workspaceDir nicht möglich ist (Fehler E_WORKSPACE_REQUIRED) und den Nutzer stattdessen auffordert, einen Ordner zu wählen. 5. Definition of Done (Zielzustand) Die Phase 2 gilt laut „Re-Assembly Plan“ erst als abgeschlossen, wenn folgender End-to-End-Test erfolgreich ist: 1. Der Nutzer wählt einen Workspace. 2. Ein Projekt wird erstellt und gespeichert. 3. Die App wird neu gestartet. 4. Das Projekt wird geladen und ist binär identisch. Analogie zur Verdeutlichung Man kann sich Phase 2 wie den Einbau eines Bank-Schalters vorstellen. Der Renderer (Kunde) darf nicht selbst in den Tresorraum (Festplatte/Main-Prozess) gehen. Er muss seine Wünsche (Daten) durch ein schusssicheres Glas (IPC Bridge) an den Bankangestellten reichen. Der Angestellte prüft zuerst den Ausweis (Whitelist) und ob das Formular korrekt ausgefüllt ist (Validierung). Dann legt er das Geld (die Datei) ausschließlich in das Schließfach des Kunden (Sandbox/Workspace) – niemals in das eines anderen (Path Traversal Protection). Phase 2 stellt sicher, dass dieses Schließfachsystem sicher und verlässlich funktioniert. Welche Sicherheitsmaßnahmen umfasst die "Phase 2" des Re-Assembly Plans? Welche drei Komponenten orchestriert der `buildService.ts` im Hauptprozess? Was ist der Unterschied zwischen den Textur-Quellen "preset" und "dataUri"? Diskutieren, was diese Quellen im Kontext von „Re-Assembly Plan“ über „Phase 3: Exporter (PNG-Assets & Java)“ aussagen.  Basierend auf dem „Re-Assembly Plan“ und den zugehörigen „Patch Plans“ ist Phase 3 der kritische Schritt, in dem das abstrakte Datenmodell (core-model) in ein physisches, kompilierbares Dateisystem (ein Fabric-Mod-Projekt) übersetzt wird. Die Quellen definieren diese Phase als Übergang zur Deterministik: Gleicher Input muss immer exakt den gleichen Output erzeugen. Hier ist eine detaillierte Diskussion dessen, was die Quellen über die Komponenten von Phase 3 aussagen: 1. Das Kernziel: Erfüllung des „Exporter Manifest v1“ Die Quellen betonen, dass der Exporter nicht „irgendwie“ Dateien schreiben darf, sondern strikt dem Exporter Manifest v1 folgen muss,. • Keine Platzhalter: Der ursprüngliche Code enthielt unfertige Stellen (...). Phase 3 verlangt, dass die Datei packages/exporter/src/index.ts vollständig implementiert wird, um das Template zu kopieren und Platzhalter wie {{MOD_ID}} oder {{MOD_NAME}} durch echte Metadaten aus der project.json zu ersetzen,. • Deterministik: Um „flaky builds“ (unzuverlässige Erstellungsprozesse) zu vermeiden, verlangt der Plan, dass JSON-Keys beim Schreiben sortiert werden und keine Zeitstempel in generierten Dateien landen,. 2. Handhabung von PNG-Assets (Texturen) Ein zentrales technisches Problem im ursprünglichen Repo war die Lücke zwischen den generierten Texturen im UI (Canvas/Base64) und dem Dateisystem. Phase 3 schließt diese Lücke durch eine strikte DataURI-Strategie. • Die dataUriToBuffer-Funktion: Die Datei packages/exporter/src/generators/assets.ts muss implementiert werden. Sie nimmt einen Base64-String (aus der project.json) entgegen, validiert das Präfix (data:image/png;base64,) und konvertiert ihn in einen binären Buffer,. • Ablagestruktur: Die Assets müssen an exakt definierten Pfaden gespeichert werden, damit Minecraft sie findet:     ◦ Blöcke: assets/<modId>/textures/block/<blockId>.png     ◦ Items: assets/<modId>/textures/item/<itemId>.png,. • Preset-Handling: Falls eine Textur als „Preset“ (z. B. „rock“) definiert ist, empfehlen die Quellen, dass das UI diese bereits vor dem Speichern in eine DataURI umgewandelt hat. Der Exporter sollte idealerweise nur noch mit DataURIs arbeiten, um die Komplexität zu reduzieren. 3. Generierung von Java-Code (Registry & Logik) Der Exporter muss validen Java-Code erzeugen, der die definierten Blöcke und Items bei der Fabric-API registriert. Dies geschieht in packages/exporter/src/generators/java.ts. • Deterministisches Package-Naming: Um Namenskonflikte zu vermeiden, wird das Java-Paket dynamisch, aber deterministisch aus der modId generiert (z. B. com.kidmodstudio.<modId>),. • Die ModRegistry.java: Diese Klasse ist das Herzstück des generierten Codes. Sie muss:     ◦ Alle Blöcke via Registries.BLOCK registrieren.     ◦ Alle Items (und BlockItems) via Registries.ITEM registrieren.     ◦ Eigenschaften mappen: Werte aus der project.json wie hardness oder luminance müssen in entsprechende Java-Methodenaufrufe (.strength(), .luminance()) übersetzt werden,. 4. Generierung von JSON-Ressourcen (Blockstates & Models) Damit die Blöcke und Items im Spiel sichtbar sind, muss Phase 3 auch die Generierung der Client-seitigen JSON-Dateien in packages/exporter/src/generators/json.ts vervollständigen,. • Lang-Files: lang/en_us.json muss die lesbaren Namen (name) den internen IDs zuordnen (z. B. "block.<modId>.<blockId>": "Mein Block"). • Modelle: Es müssen blockstates, models/block und models/item erzeugt werden. Die Quellen geben hierfür minimale, funktionierende JSON-Strukturen vor (z. B. parent: "block/cube_all" für einfache Blöcke),. 5. Der Build Runner (builder.ts) Abschließend beinhaltet Phase 3 die Reparatur des builder.ts, der den eigentlichen Kompilierungsprozess steuert. • Gradle Wrapper Detection: Der Code muss robust erkennen, ob er auf Windows (gradlew.bat) oder Unix (./gradlew) läuft,. • Execution & Logging: Der Prozess (spawn) muss gestartet, die Logs (stdout/stderr) müssen eingefangen und der Exit-Code überwacht werden. • Ergebnissicherung: Nach erfolgreichem Build muss der Runner den Pfad zur erzeugten .jar-Datei (unter build/libs/) zurückgeben. Zusammenfassung („Definition of Done“ für Phase 3) Laut dem „Assembly Plan Checklist“ ist Phase 3 abgeschlossen, wenn: 1. Der Export eines minimalen Projekts (1 Block, 1 Item) eine vollständige Dateistruktur erzeugt. 2. Der Befehl ./gradlew build im Ausgabeverzeichnis erfolgreich durchläuft. 3. Die resultierende JAR-Datei die generierten Assets (PNGs) und die kompilierten Klassen enthält,. Phase 3 transformiert also die „Single Source of Truth“ (Project JSON) in ein technisches Produkt, das von externen Tools (Java/Gradle) verarbeitet werden kann. Welche Phasen umfasst der „Re-Assembly Plan“ für das Mod Studio? Welche Aufgaben hat der „LogAnalyzer“ im Paket „testbot“? Wie stellt die „workspace.ts“ die Sicherheit des Dateisystems sicher? Diskutieren, was diese Quellen im Kontext von „Re-Assembly Plan“ über „Phase 4: Pipeline Reliability (Build & Test)“ aussagen.  Im Kontext des „Re-Assembly Plan“ für das „Minecraft Mod Studio for Kids“ markiert Phase 4: Pipeline Reliability (Build & Test) den Übergang von statischen Daten zu einer lebendigen, ausführbaren Anwendung. Nachdem in den vorherigen Phasen das Datenmodell (core-model) stabilisiert, die Persistenz (IPC) gesichert und der Exporter deterministisch gemacht wurden, widmet sich Phase 4 der Orchestrierung dieser Komponenten zu einem robusten „One-Click“-Erlebnis. Die Quellen definieren diese Phase als die Herstellung einer verlässlichen „Produktions-Story“, bei der ein Kind auf „Testen“ klickt und das System autonom exportiert, kompiliert und verifiziert. Hier ist eine detaillierte Diskussion der Aussagen der Quellen über diese Phase: 1. Zielsetzung: Von der Hoffnung zur Garantie Das Hauptziel von Phase 4 ist es, den Build-Prozess (der in frühen Versionen des Repos oft durch Platzhalter oder „Stubs“ angedeutet war) in eine belastbare Pipeline zu verwandeln. • One-Click-Pipeline: Der Prozess muss die Schritte export → build → test vollautomatisch durchlaufen. • Actionable Errors: Wenn etwas schiefgeht, darf das System nicht einfach schweigen oder kryptische Java-Stacktraces werfen. Es muss kindgerechte Fehlergründe liefern (z. B. „Dein Mod konnte nicht gebaut werden“) und Entwicklern gleichzeitig Details bieten. • Definition of Done (DoD): Die Phase gilt erst als abgeschlossen, wenn die Pipeline alle Schritte im UI anzeigt, bei Fehlern sauber abbricht und klare Gründe liefert. 2. Die Rolle des Orchestrators (buildService.ts) Das Herzstück dieser Phase ist der buildService.ts im Electron-Main-Process. Die Quellen beschreiben detaillierte Anforderungen an diese Komponente, um sie von einem Prototypen zu einem Produktions-Service zu machen: • Validierung vor Start: Bevor die Pipeline anläuft, muss das Projekt durch validateProject geprüft werden. Ungültige Projekte müssen sofort mit E_VALIDATION abgelehnt werden, um Ressourcenverschwendung zu vermeiden. • Deterministische Status-Events: Der Service muss kontinuierlich pipeline:progress-Events an das UI senden. Diese Events enthalten eine runId und einen stabilen Status (export, build, test, done, error). • Temp-Dir Management: Der Build-Prozess darf nicht im Nutzer-Workspace „herumschmieren“. Die Quellen fordern, dass Exporte in temporäre Verzeichnisse erfolgen, die nach Abschluss (oder Best-Effort) bereinigt werden. 3. Stabilisierung der „Worker“-Komponenten Phase 4 verlangt, dass die aufgerufenen Unterkomponenten (exporter und testbot) von Platzhaltern („...“) bereinigt und robust gemacht werden. A. Der Builder (builder.ts) Die Quellen betonen die Notwendigkeit einer robusten Erkennung der Build-Umgebung: • Gradle Wrapper: Das System muss erkennen, ob es auf Windows (gradlew.bat) oder Unix (./gradlew) läuft, und die Ausführungsrechte (chmod) sicherstellen. • Artefakt-Suche: Nach dem Build muss der Builder verifizieren, ob tatsächlich eine JAR-Datei im Ordner build/libs/ entstanden ist. Fehlt diese, gilt der Build als fehlgeschlagen (E_BUILD_FAILED), auch wenn der Exit-Code 0 war. B. Der Testbot (runner.ts & analyzer.ts) Da der Minecraft-Server keine strukturierte API hat, verlässt sich die Pipeline auf Log-Analyse. Phase 4 formalisiert diese Heuristiken: • Runner: Der Testbot startet den Gradle-Task runServer und muss ein Timeout (z. B. 180 Sekunden) durchsetzen, um hängende Prozesse zu killen. • Analyzer: Die Log-Analyse unterscheidet zwischen Erfolg und Absturz.     ◦ Erfolg: Erkennung von Strings wie „Done (...)! For help, type“.     ◦ Fehler: Erkennung von Crash-Mustern wie „Exception in thread“, „Mixin apply failed“ oder „Incompatible mod set“. • Feedback: Ein Timeout führt zu E_TEST_FAILED mit der Nachricht „Server did not start in time“, während ein Crash spezifische Log-Snippets extrahiert. 4. User Experience & Fehlerkultur Ein kritischer Aspekt von Phase 4 ist die Übersetzung technischer Zustände in eine kindgerechte UI. Die Quellen verweisen auf den Error Catalog v1 und das BuildDialog-UI: • UI-Stepper: Das Frontend (BuildDialog.tsx) abonniert die Progress-Events und visualisiert den Fortschritt. Wichtig ist, dass der Stepper niemals in einem Zwischenzustand „hängenbleibt“. • Fehler-Mapping: Technische Fehler werden kategorisiert:     ◦ Ein Gradle-Fehler wird zu E_BUILD_FAILED: „Dein Mod konnte nicht gebaut werden.“.     ◦ Ein Server-Crash wird zu E_TEST_FAILED: „Dein Mod wurde gebaut, aber der Test hat nicht gestartet.“. • Details für Eltern/Entwickler: Während das Kind nur die freundliche Nachricht sieht, sollen Details (Logs, Stacktraces) in einem optionalen „Details“-Panel verfügbar sein. Zusammenfassung Im Kontext des „Re-Assembly Plan“ ist Phase 4 der Moment, in dem das System „ehrlich“ wird. Es ersetzt Mock-Antworten und Platzhalter durch echte Prozesssteuerung. Die Quellen stellen klar, dass Pipeline-Reliability nicht nur bedeutet, dass der Code kompiliert, sondern dass das System beobachtbar (observable), fehlerresistent und kommunikativ gegenüber dem Nutzer ist. Analogie: Wenn Phase 1-3 das Konstruieren des Autos (Datenmodell), das Einbauen des Motors (Exporter) und das Sichern der Türen (IPC) waren, dann ist Phase 4 der erste echte Zündschlüssel-Dreh. Es geht darum sicherzustellen, dass der Motor nicht nur anspringt, sondern dass das Armaturenbrett (UI) sofort anzeigt, ob Benzin fehlt (Validation Error), der Motor überhitzt (Build Error) oder das Auto fahrbereit ist (Done). Welche Schritte umfasst die Build-Pipeline laut dem „buildService“? Wie ist das Domain-Datenmodell der „Minecraft Mod Studio“-Projekte aufgebaut? Welche Sicherheitsmaßnahmen sieht der „IPC Contract“ für den Dateisystemzugriff vor? Diskutieren, was diese Quellen im Kontext von „Minecraft Mod Studio for Kids (Repo-Analyse)“ über „Identifizierte Probleme“ aussagen.  Basierend auf den Quellen, insbesondere den Analyse-Dateien (MINEC__save..., PATCH__save...), zeichnen die Dokumente ein klares Bild vom Zustand des „Minecraft Mod Studio for Kids“-Repositories. Es wird primär als „Prototyp“ oder „Scaffold“ identifiziert, dessen Architektur zwar erkennbar, dessen Implementierung jedoch an kritischen Stellen unvollständig oder riskant ist. Die identifizierten Probleme lassen sich in fünf Hauptkategorien unterteilen: 1. Unvollständigkeit des Codes („Stubs“ und Platzhalter) Das offensichtlichste Problem, das mehrfach hervorgehoben wird, ist der Zustand vieler Dateien, die nicht kompiliert oder ausgeführt werden können, weil sie explizite Platzhalter enthalten. • Syntax-Lücken: Mehrere TypeScript-Dateien enthalten ellipsenartige Platzhalter (...) oder abgeschnittene Strings und Regex-Definitionen. Dies betrifft kritische Bereiche wie das core-model (Schema, Reducer) und den exporter,,. • Fehlende Persistenz-Logik: Die IPC-Kanäle für project:save und project:load sind im Main-Process (ipc.ts) größtenteils „Stubs“ (Platzhalter). project:save gibt zwar „success“ zurück, schreibt aber faktisch keine Daten auf die Festplatte,. • Mock-Abhängigkeit: Um diese Lücken zu kaschieren, verlässt sich der Renderer im Browser-Modus auf eine mockBridge, was dazu führt, dass Bugs im echten Electron-Umfeld maskiert werden könnten,. 2. Strukturelle Architektur-Probleme (F1–F5) Die Quellen enthalten eine explizite Liste von „Findings“ (F1 bis F5), die strukturelle Risiken bewerten,: • F1: Coupling (Kopplung): Es gibt unklare Grenzen zwischen Domain, IPC, Export und UI. Die Domain-Typen und Validierungen sind verstreut, was zu Inkonsistenzen („Drift“) führt. Wenn das core-model nicht die „Single Source of Truth“ ist, blockieren Änderungen an einer Stelle das gesamte System,. • F2: Security / Trust Boundaries: Der Renderer wird als „untrusted UI“ eingestuft, aber die aktuelle IPC-Implementierung setzt dies nicht konsequent durch. Es fehlt eine strikte „Workspace Sandbox“; Operationen im Dateisystem sind nicht ausreichend gegen „Path Traversal“-Angriffe abgesichert,. Zudem wird eine existierende VALID_CHANNELS-Whitelist im Preload nicht technisch erzwungen,. • F3: Testability (Testbarkeit): Vor dem geplanten Refactoring fehlen stabile Tests („Sicherheitsnetz“). Ein Umbau des Systems ohne funktionierende Tests für den Reducer oder den Exporter erhöht das Regressionsrisiko massiv,. • F4: Duplication (Redundanz): Es gibt doppelte Typdefinitionen zwischen Domain, Renderer und Exporter, die auseinanderzudriften drohen. • F5: Cohesion (Zusammenhalt): Einige Dateien werden als „God-Files“ beschrieben oder enthalten Logik, die dort nicht hingehört (z. B. AI-Stubs in falschen Schichten), was klare Verantwortlichkeiten verhindert. 3. Das ID-Problem (Datenintegrität) Ein spezifisches fachliches Problem wird intensiv diskutiert: Die Handhabung von IDs (block_id, item_id). • Editierbare IDs: Aktuell erlaubt das UI das Editieren von IDs. Da diese IDs jedoch als Schlüssel in Datenbank-Records (blocks, items) und als Referenzen in Rezepten verwendet werden, führt eine Umbenennung zu „broken references“ (kaputten Verknüpfungen). • Lösungsvorschlag: Die Quellen empfehlen dringend, IDs nach der Erstellung immutable (unveränderlich) zu machen oder komplexe Rename-Aktionen zu implementieren, die alle Referenzen aktualisieren („Shotgun Surgery“ vermeiden),. 4. Die „Missing Layer“ im Exporter Zwischen dem UI (Renderer) und dem Exporter klafft eine logische Lücke bei der Verarbeitung von Assets. • Texturen-Handling: Der Renderer generiert Texturen (z. B. via Canvas/DataURI), aber im Exporter-Code ist die Umwandlung dieser Daten in physische PNG-Dateien nicht vollständig sichtbar oder implementiert. • Determinismus: Der Export-Prozess ist aktuell nicht deterministisch genug definiert (z. B. unsortierte JSON-Keys), was automatisierte Tests und Reproduzierbarkeit erschwert. 5. Fehlende Fehlerkultur (Error Envelopes) Die Kommunikation zwischen den Prozessen (IPC) nutzt kein einheitliches Format für Fehler. Das macht das Debugging schwer und verhindert, dass dem Nutzer im UI (z. B. im „BuildDialog“) kindgerechte Fehlermeldungen angezeigt werden können, wenn im Backend etwas schiefgeht (z. B. E_BUILD_FAILED),. Zusammenfassung Die Analyse diagnostiziert das Repo als eine Baustelle mit klarem Plan, aber fehlendem Fundament. Die Quellen schlagen vor, das System nicht einfach „weiterzubauen“, sondern durch eine „Contract-First“-Strategie zu sanieren: Zuerst müssen die Verträge (JSON Spec, IPC Spec) fixiert und das core-model bereinigt werden, bevor an neuen Features gearbeitet wird,.  -------------------------------------------------------------------------------- Analogie: Das Repository gleicht aktuell einem Filmset-Haus: Von vorne (UI) sieht es aus wie ein fertiges Haus, und man kann die Tür öffnen (Mock-Daten). Aber wenn man versucht, tatsächlich darin zu wohnen (Speichern/Exportieren), merkt man, dass hinter der Fassade die Rohre fehlen (IPC Stubs), das Fundament Löcher hat (Core Model Placeholders) und es keine Schlösser an den Türen gibt (Security Gaps). Die Analyse ist der Bauplan, um daraus ein echtes, bewohnbares Haus zu machen. Welche drei Hauptschichten bilden die Architektur der Desktop-App? Wie stellt die Sandbox-Funktion den Schutz vor Path Traversal sicher? Welche Schritte umfasst die Build-Pipeline vom Export bis zum Test? Diskutieren, was diese Quellen im Kontext von „Identifizierte Probleme“ über „Abgeschnittener Code (Platzhalter/Ellipsen)“ aussagen.  Basierend auf den Quellen, insbesondere den Analyse-Berichten (MINEC__save...) und den Refactoring-Plänen („Patch Plan“, „Assembly Plan“), wird das Thema „Abgeschnittener Code (Platzhalter/Ellipsen)“ als eines der kritischsten Probleme für die Wiederherstellung („Assembly“) des „Minecraft Mod Studio for Kids“ identifiziert. Die Quellen treffen dazu folgende Aussagen: 1. Diagnose: Prototyp-Status statt Produktions-Code Die Quellen stellen fest, dass das Repository in weiten Teilen nicht in einem sofort kompilierbaren Zustand ist. • Beobachtung: Mehrere zentrale TypeScript-Dateien enthalten sichtbare textuelle Platzhalter wie ... oder abrupt endende Codezeilen (z. B. action.pay... oder abgeschnittene Regex-Strings). • Interpretation: Dies deutet darauf hin, dass es sich bei dem vorliegenden Code um ein „Scaffold“ (Gerüst) oder einen Prototypen handelt. Die Architektur und die „Nähte“ (Schnittstellen) sind zwar klar erkennbar, aber die eigentliche Implementierung ist an diesen Stellen unvollständig,. 2. Betroffene Kernbereiche („Hotspots“) Das Problem ist nicht auf unwichtige Nebenbereiche beschränkt, sondern betrifft das fundamentale Datenmodell und die Build-Logik: • Core-Model (Das Herzstück):     ◦ Schema: Zod-Definitionen enthalten Platzhalter. Beispielsweise sind Regex-Regeln für IDs oder Strukturen für Block/Item nicht vollständig ausgeführt.     ◦ Actions & Reducer: Die Definitionen der KidAction-Union (z. B. LOAD_PROJECT) und die Reducer-Logik enthalten unvollständige Payloads oder abgeschnittene Zuweisungen,. Dies verhindert eine typsichere State-Verwaltung. • Exporter:     ◦ Code-Generierung: In den Generatoren (z. B. generators/java.ts) bricht die String-Interpolation ab (z. B. ${s...), was zu Syntaxfehlern im exportierten Java-Code führen würde.     ◦ Logik-Lücken: Funktionen wie exportProject sind im index.ts stark abgeschnitten, was den Export-Prozess funktionsunfähig macht. 3. Risiko für die Rekonstruktion Die Quellen klassifizieren diese Platzhalter als „Risiko“ und „Unsicherheitsfaktor“. • Blocker: Man kann nicht bestätigen, ob das Projekt baubar ist, solange diese Stellen nicht bereinigt sind („placeholder cleanup“). • Intent vs. Implementation: Die Quellen betonen, dass man an diesen Stellen den „Design Intent“ (die Absicht) ablesen kann, aber keine laufende Implementierung vorfindet. Das Refactoring muss diese Lücken also basierend auf der architektonischen Absicht füllen, nicht durch bloßes Kopieren. 4. Lösungsstrategie: „Core Truth“ Stabilisierung Als Reaktion auf dieses identifizierte Problem definieren die Quellen eine strikte „Phase 1“ im Assembly-Plan, die sich ausschließlich der Beseitigung dieser Ellipsen widmet. • Priorität: Bevor UI oder IPC bearbeitet werden, muss das core-model zu 100% sauber sein („no placeholders (...) remain“). • Konkrete Maßnahmen:     ◦ Das Schema (schema.ts) muss vollständig ausformuliert werden, um exakt der „Project JSON Spec“ zu entsprechen.     ◦ Der Reducer (reducer.ts) muss repariert werden, um deterministische Updates ohne any-Platzhalter zu gewährleisten.     ◦ Erst wenn diese „Single Source of Truth“ frei von Platzhaltern ist, dürfen darauf aufbauende Komponenten (Exporter, UI) integriert werden, um eine Fehlerfortpflanzung zu verhindern. Zusammenfassung Im Kontext der identifizierten Probleme sagen die Quellen aus, dass der abgeschnittene Code das primäre Hindernis für die Funktionsfähigkeit ist. Er markiert den Unterschied zwischen einem theoretischen Architekturmodell und einer realen Anwendung. Die Strategie lautet daher: Nicht einfach die Lücken füllen, sondern die betroffenen Dateien (Schema, Reducer, Exporter) basierend auf den definierten Verträgen (Contracts) komplett neu und sauber implementieren, um das „Prototyp-Gerüst“ in ein stabiles Fundament zu verwandeln,. Welche drei Komponenten umfasst die Build-Pipeline laut `buildService.ts`? Welche Sicherheitsregeln muss der Main-Prozess laut IPC-Spec erzwingen? In welchen fünf Phasen soll das System laut „Wiring Plan“ zusammengesetzt werden? Welche Sicherheitsregeln muss der Main-Prozess bei Dateioperationen zwingend erzwingen?  Basierend auf den Quellen, insbesondere der „IPC / Bridge Spec v1“ und dem „Assembly Plan“, muss der Main-Prozess (Electron Main) als alleinige Autorität über das Dateisystem agieren. Da der Renderer (die Benutzeroberfläche) als „untrusted UI“ eingestuft wird, gelten folgende zwingende Sicherheitsregeln für Dateioperationen: 1. Durchsetzung der „Workspace Sandbox“ (Schutz vor Path Traversal) Dies ist die wichtigste Regel. Der Main-Prozess darf niemals Dateipfade akzeptieren, die aus dem definierten Projektordner ausbrechen. • Keine absoluten Pfade vom Renderer: Der Main-Prozess akzeptiert keine Zieldateinamen (wie „C:/windows/...“) vom Renderer. Er akzeptiert nur das workspaceDir und definiert den Dateinamen (project.json) intern selbst. • Verwendung von safeJoin: Pfade müssen im Main-Prozess über Hilfsfunktionen wie safeJoin(workspaceDir, relativePath) oder assertInWorkspace aufgelöst werden,. • Blockieren von Ausbruchsversuchen: Versucht der Renderer, Pfade wie ../../passwords.txt zu übergeben, muss die Operation sofort abgebrochen und der Fehlercode E_PATH_TRAVERSAL zurückgegeben werden,. 2. Validierung vor der Persistierung (validateProject) Der Main-Prozess darf Daten nicht blind auf die Festplatte schreiben. Er fungiert als Wächter der Datenintegrität. • Schema-Prüfung: Bevor ein project:save-Befehl ausgeführt wird, muss das empfangene JSON-Objekt durch die Funktion validateProject (aus dem core-model) laufen. • Ablehnung ungültiger Daten: Wenn die Validierung fehlschlägt (z. B. fehlende IDs, ungültige Referenzen), darf nicht gespeichert werden. Stattdessen muss der Fehler E_VALIDATION an den Renderer zurückgemeldet werden,. Dies verhindert, dass korrupte Dateien im Dateisystem landen. 3. Atomares Schreiben (Atomic Writes) Um Datenverlust bei Abstürzen (z. B. Stromausfall während des Speicherns) zu verhindern, schreibt der Vertrag eine atomare Operation vor. • Temp-Datei Strategie: Der Main-Prozess schreibt die Daten zuerst in eine temporäre Datei (z. B. project.json.tmp). • Umbenennen: Erst wenn dieser Schreibvorgang erfolgreich abgeschlossen ist, wird die temporäre Datei in die echte project.json umbenannt (ersetzt),. 4. Whitelisting der IPC-Kanäle Obwohl dies eher die Kommunikation betrifft, schützt es indirekt das Dateisystem. • Strikte Kanalliste: Im Preload-Skript (bridge.ts) darf nur eine explizite Liste von Kanälen (z. B. project:save, project:load) durchgelassen werden. • Keine generischen FS-APIs: Es darf keinen generischen Kanal geben wie fs:write(path, content), den der Renderer missbrauchen könnte. Zusammenfassung Der Main-Prozess muss garantieren, dass jede Dateioperation: 1. Innerhalb des erlaubten Ordners bleibt (Sandbox). 2. Inhaltlich korrekt ist (Validierung). 3. Technisch sicher abgeschlossen wird (Atomizität).  -------------------------------------------------------------------------------- Analogie: Stellen Sie sich den Main-Prozess als einen Notar vor und den Renderer als einen Klienten. Der Klient (Renderer) kann dem Notar nicht einfach ein fertiges Dokument in den Tresor legen (kein direkter Schreibzugriff). Er muss dem Notar den Inhalt diktieren. Der Notar prüft zuerst, ob der Inhalt legal und vollständig ist (Validierung). Dann schreibt der Notar das Dokument selbst, legt es in einen vorläufigen Umschlag (Temp-Datei) und erst, wenn alles fertig unterschrieben ist, schließt er es in das zugewiesene Schließfach des Klienten (Sandbox) – niemals in das Schließfach eines anderen Kunden oder in den Safe der Bankverwaltung (Path Traversal Protection). Welche drei Phasen umfasst die Build-Pipeline im BuildService? Welche Aufgaben übernimmt das Paket @kidmodstudio/exporter im Monorepo?